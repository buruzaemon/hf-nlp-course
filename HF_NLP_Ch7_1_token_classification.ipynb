{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "74b4bae2-beb3-4746-b4e7-14f182a1e3a2",
   "metadata": {},
   "source": [
    "# NLP Course\n",
    "\n",
    "Please see the [Hugging Face NLP Course page](https://huggingface.co/learn/nlp-course/chapter0/1?fw=pt)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "061a200e-5a76-436c-be6f-61f893caa567",
   "metadata": {},
   "source": [
    "## 7. Main NLP Tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97076774-f4b7-4a26-b1b7-3997cef457e1",
   "metadata": {},
   "source": [
    "### Token classification\n",
    "\n",
    "#### Objective\n",
    "\n",
    "We will fine-tune the BERT model [`bert-base-cased`](https://huggingface.co/google-bert/bert-base-cased) for the Named Entity Recognition task.\n",
    "\n",
    "> BERT is a transformers model pretrained on a large corpus of English data in a self-supervised fashion.\n",
    ">\n",
    "> More precisely, it was pretrained with two objectives:<p/>\n",
    "> * Masked language modeling (MLM): taking a sentence, the model randomly masks 15% of the words in the input then run the entire masked sentence through the model and has to predict the masked words.<br/>\n",
    "> * Next sentence prediction (NSP): the models concatenates two masked sentences as inputs during pretraining.\n",
    ">z\n",
    "> This way, the model learns an inner representation of the English language that can then be used to extract features\n",
    "> useful for downstream tasks: if you have a dataset of labeled sentences for instance, you can train a standard\n",
    "> classifier using the features produced by the BERT model as inputs.\n",
    "\n",
    "\n",
    "\n",
    "Please see [Token Classification](https://huggingface.co/learn/nlp-course/chapter7/2?fw=pt#token-classification), 7. Main NLP Tasks, in the ðŸ¤— NLP Course."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "750e3595-51ab-4cf1-b4e3-9358f2cdd96e",
   "metadata": {},
   "source": [
    "#### Preparing the data\n",
    "\n",
    "> In this section we will use the CoNLL-2003 dataset (please see [`eriktks/conll2003`](https://huggingface.co/datasets/eriktks/conll2003), which contains news stories from Reuters.\n",
    "\n",
    "Please also see [Introduction to the CoNLL-2003 Shared Task: Language-Independent Named Entity Recognition, Sang and Meulder, 2003](https://aclanthology.org/W03-0419.pdf):\n",
    "> The shared task of CoNLL-2003 concerns language-independent named entity recognition. We will concentrate on four types of named entities: persons, locations, organizations and names of miscellaneous entities that do not belong to the previous three groups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3940fe49-4610-4369-8b1f-d2b793a4c772",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "raw_datasets = load_dataset(\"conll2003\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "84fd2539-1344-4402-b945-92c516299381",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['id', 'tokens', 'pos_tags', 'chunk_tags', 'ner_tags'],\n",
      "        num_rows: 14041\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['id', 'tokens', 'pos_tags', 'chunk_tags', 'ner_tags'],\n",
      "        num_rows: 3250\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['id', 'tokens', 'pos_tags', 'chunk_tags', 'ner_tags'],\n",
      "        num_rows: 3453\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "print(raw_datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "38718c95-5fb5-4f23-ab71-95687d55fc09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['EU', 'rejects', 'German', 'call', 'to', 'boycott', 'British', 'lamb', '.']\n",
      "9 tokens\n"
     ]
    }
   ],
   "source": [
    "print(raw_datasets[\"train\"][0][\"tokens\"])\n",
    "print(f'{len(raw_datasets[\"train\"][0][\"tokens\"])} tokens')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "496520d5-923a-4d05-a51c-22777f3a6ee4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3, 0, 7, 0, 0, 0, 7, 0, 0]\n",
      "9 NER tags\n"
     ]
    }
   ],
   "source": [
    "print(raw_datasets[\"train\"][0][\"ner_tags\"])\n",
    "print(f'{len(raw_datasets[\"train\"][0][\"ner_tags\"])} NER tags')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d2fbc26-fac4-4eee-943c-b6cfdea30ede",
   "metadata": {},
   "source": [
    "The features in a dataset are referenced by the `features` attribute, which is an instance of [`datasets.Features`](https://huggingface.co/docs/datasets/v3.3.1/en/package_reference/main_classes#datasets.Features)\n",
    "\n",
    "> A special dictionary that defines the internal structure of a dataset.\n",
    ">\n",
    "> Instantiated with a dictionary of type `dict[str, FieldType]`, where keys are the desired column names, and values are the type of that column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a40b1678-b04f-4db5-a443-8390ef9c7f5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequence(feature=ClassLabel(names=['O', 'B-PER', 'I-PER', 'B-ORG', 'I-ORG', 'B-LOC', 'I-LOC', 'B-MISC', 'I-MISC'], id=None), length=-1, id=None)\n"
     ]
    }
   ],
   "source": [
    "ner_feature = raw_datasets[\"train\"].features[\"ner_tags\"]\n",
    "\n",
    "print(ner_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dbe62b47-6ceb-4d18-a889-db97aec867b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['O', 'B-PER', 'I-PER', 'B-ORG', 'I-ORG', 'B-LOC', 'I-LOC', 'B-MISC', 'I-MISC']\n"
     ]
    }
   ],
   "source": [
    "label_names = ner_feature.feature.names\n",
    "\n",
    "print(label_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52214d0c-ef4e-4fca-91cd-025397087e01",
   "metadata": {},
   "source": [
    "##### Examining the NER tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4730f7d6-0563-4656-b905-81b7ec34c43d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EU    rejects German call to boycott British lamb . \n",
      "B-ORG O       B-MISC O    O  O       B-MISC  O    O \n"
     ]
    }
   ],
   "source": [
    "words = raw_datasets[\"train\"][0][\"tokens\"]\n",
    "labels = raw_datasets[\"train\"][0][\"ner_tags\"]\n",
    "\n",
    "line1 = \"\"\n",
    "line2 = \"\"\n",
    "for word, label in zip(words, labels):\n",
    "    full_label = label_names[label]\n",
    "    max_length = max(len(word), len(full_label))\n",
    "    line1 += word + \" \" * (max_length - len(word) + 1)\n",
    "    line2 += full_label + \" \" * (max_length - len(full_label) + 1)\n",
    "\n",
    "print(line1)\n",
    "print(line2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e3a14708-1a4c-403a-a239-fc96ae65e561",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Germany 's representative to the European Union 's veterinary committee Werner Zwingmann said on Wednesday consumers should buy sheepmeat from countries other than Britain until the scientific advice was clearer . \n",
      "B-LOC   O  O              O  O   B-ORG    I-ORG O  O          O         B-PER  I-PER     O    O  O         O         O      O   O         O    O         O     O    B-LOC   O     O   O          O      O   O       O \n"
     ]
    }
   ],
   "source": [
    "words = raw_datasets[\"train\"][4][\"tokens\"]\n",
    "labels = raw_datasets[\"train\"][4][\"ner_tags\"]\n",
    "\n",
    "line1 = \"\"\n",
    "line2 = \"\"\n",
    "for word, label in zip(words, labels):\n",
    "    full_label = label_names[label]\n",
    "    max_length = max(len(word), len(full_label))\n",
    "    line1 += word + \" \" * (max_length - len(word) + 1)\n",
    "    line2 += full_label + \" \" * (max_length - len(full_label) + 1)\n",
    "\n",
    "print(line1)\n",
    "print(line2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd1fa5ff-bc22-4aea-b5ed-7769e531c217",
   "metadata": {},
   "source": [
    "âœï¸ Your turn! Print the same two sentences with their POS or chunking labels."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdb4f6c8-59c3-4cb9-bbf2-a603c3262ce2",
   "metadata": {},
   "source": [
    "##### Examining the POS tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ea7190dc-b6a5-46e7-a5fc-371925e5e832",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequence(feature=ClassLabel(names=['\"', \"''\", '#', '$', '(', ')', ',', '.', ':', '``', 'CC', 'CD', 'DT', 'EX', 'FW', 'IN', 'JJ', 'JJR', 'JJS', 'LS', 'MD', 'NN', 'NNP', 'NNPS', 'NNS', 'NN|SYM', 'PDT', 'POS', 'PRP', 'PRP$', 'RB', 'RBR', 'RBS', 'RP', 'SYM', 'TO', 'UH', 'VB', 'VBD', 'VBG', 'VBN', 'VBP', 'VBZ', 'WDT', 'WP', 'WP$', 'WRB'], id=None), length=-1, id=None)\n"
     ]
    }
   ],
   "source": [
    "pos_feature = raw_datasets[\"train\"].features[\"pos_tags\"]\n",
    "\n",
    "print(pos_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "21ff6c90-a4fa-429a-bd21-2aef16c77ed2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\"', \"''\", '#', '$', '(', ')', ',', '.', ':', '``', 'CC', 'CD', 'DT', 'EX', 'FW', 'IN', 'JJ', 'JJR', 'JJS', 'LS', 'MD', 'NN', 'NNP', 'NNPS', 'NNS', 'NN|SYM', 'PDT', 'POS', 'PRP', 'PRP$', 'RB', 'RBR', 'RBS', 'RP', 'SYM', 'TO', 'UH', 'VB', 'VBD', 'VBG', 'VBN', 'VBP', 'VBZ', 'WDT', 'WP', 'WP$', 'WRB']\n"
     ]
    }
   ],
   "source": [
    "label_names = pos_feature.feature.names\n",
    "\n",
    "print(label_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3d8b4148-09a0-476c-b6f5-39dddbb7b9c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EU  rejects German call to boycott British lamb . \n",
      "NNP VBZ     JJ     NN   TO VB      JJ      NN   . \n"
     ]
    }
   ],
   "source": [
    "words = raw_datasets[\"train\"][0][\"tokens\"]\n",
    "labels = raw_datasets[\"train\"][0][\"pos_tags\"]\n",
    "\n",
    "line1 = \"\"\n",
    "line2 = \"\"\n",
    "for word, label in zip(words, labels):\n",
    "    full_label = label_names[label]\n",
    "    max_length = max(len(word), len(full_label))\n",
    "    line1 += word + \" \" * (max_length - len(word) + 1)\n",
    "    line2 += full_label + \" \" * (max_length - len(full_label) + 1)\n",
    "\n",
    "print(line1)\n",
    "print(line2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eaf1e754-3b39-4953-abb5-c387a0856094",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Germany 's  representative to the European Union 's  veterinary committee Werner Zwingmann said on Wednesday consumers should buy sheepmeat from countries other than Britain until the scientific advice was clearer . \n",
      "NNP     POS NN             TO DT  NNP      NNP   POS JJ         NN        NNP    NNP       VBD  IN NNP       NNS       MD     VB  NN        IN   NNS       JJ    IN   NNP     IN    DT  JJ         NN     VBD JJR     . \n"
     ]
    }
   ],
   "source": [
    "words = raw_datasets[\"train\"][4][\"tokens\"]\n",
    "labels = raw_datasets[\"train\"][4][\"pos_tags\"]\n",
    "\n",
    "line1 = \"\"\n",
    "line2 = \"\"\n",
    "for word, label in zip(words, labels):\n",
    "    full_label = label_names[label]\n",
    "    max_length = max(len(word), len(full_label))\n",
    "    line1 += word + \" \" * (max_length - len(word) + 1)\n",
    "    line2 += full_label + \" \" * (max_length - len(full_label) + 1)\n",
    "\n",
    "print(line1)\n",
    "print(line2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13e70482-f838-4733-be0b-980aa6372567",
   "metadata": {},
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd464185-ba3f-42fd-801e-a8db49d3c113",
   "metadata": {},
   "source": [
    "##### Examining the Chunking labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e755e920-b7a0-430f-b44d-80ac92d34b52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequence(feature=ClassLabel(names=['O', 'B-ADJP', 'I-ADJP', 'B-ADVP', 'I-ADVP', 'B-CONJP', 'I-CONJP', 'B-INTJ', 'I-INTJ', 'B-LST', 'I-LST', 'B-NP', 'I-NP', 'B-PP', 'I-PP', 'B-PRT', 'I-PRT', 'B-SBAR', 'I-SBAR', 'B-UCP', 'I-UCP', 'B-VP', 'I-VP'], id=None), length=-1, id=None)\n"
     ]
    }
   ],
   "source": [
    "chunk_feature = raw_datasets[\"train\"].features[\"chunk_tags\"]\n",
    "print(chunk_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7f789831-1529-44cb-8cf9-5915bef8f19b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['O', 'B-ADJP', 'I-ADJP', 'B-ADVP', 'I-ADVP', 'B-CONJP', 'I-CONJP', 'B-INTJ', 'I-INTJ', 'B-LST', 'I-LST', 'B-NP', 'I-NP', 'B-PP', 'I-PP', 'B-PRT', 'I-PRT', 'B-SBAR', 'I-SBAR', 'B-UCP', 'I-UCP', 'B-VP', 'I-VP']\n"
     ]
    }
   ],
   "source": [
    "label_names = chunk_feature.feature.names\n",
    "print(label_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dd8aec8e-b77a-424d-baaf-c742985ca55e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EU   rejects German call to   boycott British lamb . \n",
      "B-NP B-VP    B-NP   I-NP B-VP I-VP    B-NP    I-NP O \n"
     ]
    }
   ],
   "source": [
    "words = raw_datasets[\"train\"][0][\"tokens\"]\n",
    "labels = raw_datasets[\"train\"][0][\"chunk_tags\"]\n",
    "\n",
    "line1 = \"\"\n",
    "line2 = \"\"\n",
    "for word, label in zip(words, labels):\n",
    "    full_label = label_names[label]\n",
    "    max_length = max(len(word), len(full_label))\n",
    "    line1 += word + \" \" * (max_length - len(word) + 1)\n",
    "    line2 += full_label + \" \" * (max_length - len(full_label) + 1)\n",
    "\n",
    "print(line1)\n",
    "print(line2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d19b9c3a-68e7-466b-807b-015607a14d88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Germany 's   representative to   the  European Union 's   veterinary committee Werner Zwingmann said on   Wednesday consumers should buy  sheepmeat from countries other  than Britain until  the  scientific advice was  clearer . \n",
      "B-NP    B-NP I-NP           B-PP B-NP I-NP     I-NP  B-NP I-NP       I-NP      I-NP   I-NP      B-VP B-PP B-NP      I-NP      B-VP   I-VP B-NP      B-PP B-NP      B-ADJP B-PP B-NP    B-SBAR B-NP I-NP       I-NP   B-VP B-ADJP  O \n"
     ]
    }
   ],
   "source": [
    "words = raw_datasets[\"train\"][4][\"tokens\"]\n",
    "labels = raw_datasets[\"train\"][4][\"chunk_tags\"]\n",
    "\n",
    "line1 = \"\"\n",
    "line2 = \"\"\n",
    "for word, label in zip(words, labels):\n",
    "    full_label = label_names[label]\n",
    "    max_length = max(len(word), len(full_label))\n",
    "    line1 += word + \" \" * (max_length - len(word) + 1)\n",
    "    line2 += full_label + \" \" * (max_length - len(full_label) + 1)\n",
    "\n",
    "print(line1)\n",
    "print(line2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a2c3bca-82b0-4577-8c76-bdd212e96800",
   "metadata": {},
   "source": [
    "#### Processing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3a33882f-76ad-424d-94c7-cb039d5c368a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "let's see some info on this tokenizer...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'do_lower_case': False,\n",
       " 'unk_token': '[UNK]',\n",
       " 'sep_token': '[SEP]',\n",
       " 'pad_token': '[PAD]',\n",
       " 'cls_token': '[CLS]',\n",
       " 'mask_token': '[MASK]',\n",
       " 'tokenize_chinese_chars': True,\n",
       " 'strip_accents': None,\n",
       " 'model_max_length': 512,\n",
       " 'name_or_path': 'bert-base-cased'}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "model_checkpoint = \"bert-base-cased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n",
    "\n",
    "print(\"let's see some info on this tokenizer...\")\n",
    "tokenizer.init_kwargs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "eac8dd91-2388-4c92-b747-54f407c0e64f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.is_fast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e0c85888-098d-45ab-950c-f71f750861b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[CLS]',\n",
       " 'EU',\n",
       " 'rejects',\n",
       " 'German',\n",
       " 'call',\n",
       " 'to',\n",
       " 'boycott',\n",
       " 'British',\n",
       " 'la',\n",
       " '##mb',\n",
       " '.',\n",
       " '[SEP]']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = tokenizer(raw_datasets[\"train\"][0][\"tokens\"], is_split_into_words=True)\n",
    "inputs.tokens()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b78a96fe-2e6f-4c54-b918-c654a9f268fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[None, 0, 1, 2, 3, 4, 5, 6, 7, 7, 8, None]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.word_ids()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5dbbe47-89ee-4698-b808-bcc6c62a7f6f",
   "metadata": {},
   "source": [
    "##### Aligning the tokens with their corresponding labels\n",
    "\n",
    "* The `tokens` are the words that the NER tags correspond with, and also _include_ the special tokens like `[CLS]` or `[SEP]`.\n",
    "* **However**, `word_ids` only list `None` for those special tokens.\n",
    "\n",
    "> The first rule weâ€™ll apply is that special tokens get a label of `-100`.\n",
    "> <span style=\"background-color:#33FFFF\">This is because by default `-100` is an index that is ignored in the loss\n",
    "> function we will use (cross entropy)</span>\n",
    "\n",
    "We define a function `align_labels_with_tokens` that will take care of this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "540e84a8-8e61-453f-98c7-3f23414bf03a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def align_labels_with_tokens(labels, word_ids):\n",
    "    new_labels = []\n",
    "    current_word = None\n",
    "    for word_id in word_ids:\n",
    "        if word_id != current_word:\n",
    "            # Start of a new word!\n",
    "            current_word = word_id\n",
    "            label = -100 if word_id is None else labels[word_id]\n",
    "            new_labels.append(label)\n",
    "        elif word_id is None:\n",
    "            # Special token\n",
    "            new_labels.append(-100)\n",
    "        else:\n",
    "            # Same word as previous token\n",
    "            label = labels[word_id]\n",
    "            # If the label is B-XXX we change it to I-XXX\n",
    "            if label % 2 == 1:\n",
    "                label += 1\n",
    "            new_labels.append(label)\n",
    "\n",
    "    return new_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c07a0af0-6816-4f76-9bc9-8197759a16ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labels: [3, 0, 7, 0, 0, 0, 7, 0, 0]\n",
      "word_ids: [None, 0, 1, 2, 3, 4, 5, 6, 7, 7, 8, None]\n",
      "\n",
      "after correction: [-100, 3, 0, 7, 0, 0, 0, 7, 0, 0, 0, -100]\n"
     ]
    }
   ],
   "source": [
    "labels = raw_datasets[\"train\"][0][\"ner_tags\"]\n",
    "word_ids = inputs.word_ids()\n",
    "\n",
    "print(f\"labels: {labels}\")\n",
    "print(f\"word_ids: {word_ids}\")\n",
    "print()\n",
    "print(f\"after correction: {align_labels_with_tokens(labels, word_ids)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e755ba2d-a516-4002-84b0-4697bae72bf6",
   "metadata": {},
   "source": [
    "âœï¸ Your turn! Some researchers prefer to attribute only one label per word, and assign -100 to the other subtokens in a given word. This is to avoid long words that split into lots of subtokens contributing heavily to the loss. Change the previous function to align labels with input IDs by following this rule."
   ]
  },
  {
   "cell_type": "raw",
   "id": "51cb56f5-ca3b-4a1e-bfab-ed2858b8722b",
   "metadata": {},
   "source": [
    "def align_labels_with_tokens2(labels, word_ids):\n",
    "    new_labels = []\n",
    "    current_word = None\n",
    "    for word_id in word_ids:\n",
    "        if word_id != current_word:\n",
    "            # Start of a new word!\n",
    "            current_word = word_id\n",
    "            label = -100 if word_id is None else labels[word_id]\n",
    "            #print(f\"!= current_word: {label}\")\n",
    "            new_labels.append(label)\n",
    "        elif word_id is None:\n",
    "            # Special token\n",
    "            #print(\"special token\")\n",
    "            new_labels.append(-100)\n",
    "        else:\n",
    "            # Same word as previous token\n",
    "            #label = labels[word_id]\n",
    "            # If the label is B-XXX we change it to I-XXX\n",
    "            #if label % 2 == 1:\n",
    "            #    label += 1\n",
    "            label = -100\n",
    "            #print(f\"same as previous token: {label}\")\n",
    "            new_labels.append(label)\n",
    "\n",
    "\n",
    "    return new_labels"
   ]
  },
  {
   "cell_type": "raw",
   "id": "2bd7aeae-4406-4e43-812c-7380b004d0c3",
   "metadata": {},
   "source": [
    "print(labels)\n",
    "print(align_labels_with_tokens2(labels, word_ids))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ada445a-85e2-4458-b1f4-cfb2e9090ead",
   "metadata": {},
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5ea1a72-0736-43bb-8143-6e469abe8d1a",
   "metadata": {},
   "source": [
    "> To preprocess our whole dataset, we need to tokenize all the inputs and apply `align_labels_with_tokens()` on all the labels. To take advantage of the speed of our fast tokenizer, itâ€™s best to tokenize lots of texts at the same time, so weâ€™ll write a function that processes a list of examples and use the `Dataset.map()` method with the option `batched=True`. The only thing that is different from our previous example is that the `word_ids()` function needs to get the index of the example we want the word IDs of when the inputs to the tokenizer are lists of texts (or in our case, list of lists of words), so we add that too\n",
    "\n",
    "N.B. this `tokenize_and_align_labels` is designed so that it can work on a short array of examples as well as on a batch invoked via [ðŸ¤— Datasets batch mapping](https://huggingface.co/docs/datasets/about_map_batch#batch-mapping)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "05412440-e941-489b-ab52-c03a8f28fade",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_and_align_labels(examples):\n",
    "    tokenized_inputs = tokenizer(\n",
    "        examples[\"tokens\"], truncation=True, is_split_into_words=True\n",
    "    )\n",
    "    all_labels = examples[\"ner_tags\"]\n",
    "    new_labels = []\n",
    "    for i, labels in enumerate(all_labels):\n",
    "        word_ids = tokenized_inputs.word_ids(i)\n",
    "        new_labels.append(align_labels_with_tokens(labels, word_ids))\n",
    "\n",
    "    tokenized_inputs[\"labels\"] = new_labels\n",
    "    return tokenized_inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c461ee81-b567-4d0b-9d98-cbf20a5229e6",
   "metadata": {},
   "source": [
    "Let's test this out on a very small slice of the training examples..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d7926f5a-7708-47ae-9495-5a2c52680c82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': [[101, 7270, 22961, 1528, 1840, 1106, 21423, 1418, 2495, 12913, 119, 102], [101, 1943, 14428, 102]], 'token_type_ids': [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1]], 'labels': [[-100, 3, 0, 7, 0, 0, 0, 7, 0, 0, 0, -100], [-100, 1, 2, -100]]}\n"
     ]
    }
   ],
   "source": [
    "print(tokenize_and_align_labels(raw_datasets[\"train\"][:2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0721b61-2ef3-4fd2-b3ad-c48e834b82d5",
   "metadata": {},
   "source": [
    "Now let's transform the raw dataset (train, validation, and test sets) all in one go, putting the data into a form that we can use for our fine-tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d00218ff-11eb-42c6-8b63-21bfdbc2a7b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_datasets = raw_datasets.map(\n",
    "    tokenize_and_align_labels,\n",
    "    batched=True,\n",
    "    remove_columns=raw_datasets[\"train\"].column_names,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b7bb37e-cd35-4501-997e-76b7cd89bcb4",
   "metadata": {},
   "source": [
    "The raw dataset has these columns..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "caa3998c-acc6-4f98-bbcd-8cf0676c0a65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['id', 'tokens', 'pos_tags', 'chunk_tags', 'ner_tags']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_datasets[\"train\"].column_names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4266c8b4-ac56-49cb-a983-d354b4abb16f",
   "metadata": {},
   "source": [
    "And our transformed data for fine-tuning has these columns..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "627d27d2-dff2-4d3c-9bac-c44f9c1eba10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': ['input_ids', 'token_type_ids', 'attention_mask', 'labels'],\n",
       " 'validation': ['input_ids', 'token_type_ids', 'attention_mask', 'labels'],\n",
       " 'test': ['input_ids', 'token_type_ids', 'attention_mask', 'labels']}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_datasets.column_names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0006feb9-4baa-439c-89b0-76499b090181",
   "metadata": {},
   "source": [
    "<span style=\"background-color:#AFFF33;\">**Q?** How to confirm the column names? Where do they come from? The tokenizer? the model?</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e64b719-2518-4083-98ba-d7b8aee9c273",
   "metadata": {},
   "source": [
    "#### Fine-tuning the model with the Trainer API"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "393a6dac-7967-4261-84ed-305f4ce48cd3",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    " #### Data collation\n",
    "\n",
    "> We canâ€™t just use a [`DataCollatorWithPadding`](https://huggingface.co/docs/transformers/main_classes/data_collator#transformers.DataCollatorWithPadding)\n",
    "> like in Chapter 3 because that only pads the inputs (input IDs, attention mask, and token type IDs).\n",
    "> <span style=\"background-color:#33FFFF\">Here our labels should be padded the exact same way\n",
    "> as the inputs so that they stay the same size, using `-100` as a value so that the corresponding\n",
    "> predictions are ignored in the loss computation</span>\n",
    ">\n",
    "> This is all done by a [`DataCollatorForTokenClassification`](https://huggingface.co/docs/transformers/main_classes/data_collator#transformers.DataCollatorForTokenClassification). Like the `DataCollatorWithPadding`, <span style=\"background-color:#33FFFF\">it takes the tokenizer used to preprocess the inputs</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d5a35c94-a961-4302-9e27-35fc833ff1dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorForTokenClassification\n",
    "\n",
    "data_collator = DataCollatorForTokenClassification(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e568614-4c9a-4c1b-b680-6bf1eed080e9",
   "metadata": {},
   "source": [
    "Just to see, let's take another look at the raw example at index 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5097cba0-d206-49e8-a6bd-8df15a69f545",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': '1',\n",
       " 'tokens': ['Peter', 'Blackburn'],\n",
       " 'pos_tags': [22, 22],\n",
       " 'chunk_tags': [11, 12],\n",
       " 'ner_tags': [1, 2]}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_datasets[\"train\"][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3ab8734-5737-44a1-8606-f5118319e606",
   "metadata": {},
   "source": [
    "Compare that to the tokenized example at index 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "553f03b9-4b5b-4e8a-98d1-1788d3c31fa2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [101, 1943, 14428, 102],\n",
       " 'token_type_ids': [0, 0, 0, 0],\n",
       " 'attention_mask': [1, 1, 1, 1],\n",
       " 'labels': [-100, 1, 2, -100]}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_datasets[\"train\"][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83d62c79-53ac-481e-9b8d-403f9a97824e",
   "metadata": {},
   "source": [
    "And then compare the above raw and tokenized examples with what happens when we have a (mini) batch:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a89c5781-f73d-45ff-9c58-e335111092a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-100,    3,    0,    7,    0,    0,    0,    7,    0,    0,    0, -100],\n",
      "        [-100,    1,    2, -100, -100, -100, -100, -100, -100, -100, -100, -100]])\n",
      "\n",
      "see how the 2nd row (example at index 1) is nicely padded (on the right) to match the length of the 1st row (example at index 0)?\n"
     ]
    }
   ],
   "source": [
    "batch = data_collator([tokenized_datasets[\"train\"][i] for i in range(2)])\n",
    "\n",
    "print(batch[\"labels\"])\n",
    "print()\n",
    "print(\"see how the 2nd row (example at index 1) is nicely padded (on the right) to match the length of the 1st row (example at index 0)?\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "2322cdab-bb61-4970-be56-552c2f6409dc",
   "metadata": {},
   "source": [
    "for i in range(2):\n",
    "    print(tokenized_datasets[\"train\"][i][\"labels\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cab034d-0229-4e7a-aecc-1253bf058d9c",
   "metadata": {},
   "source": [
    "#### Metrics\n",
    "\n",
    "From [Metric: sequeval](https://huggingface.co/spaces/evaluate-metric/seqeval) on ðŸ¤— Spaces:\n",
    "\n",
    "> Seqeval produces labelling scores along with its sufficient statistics from a source against one or more references.\n",
    ">\n",
    "> It takes two mandatory arguments:\n",
    "> <br/><span style=\"padding-left:20px;\"/><tt>predictions</tt>: a list of lists of predicted labels, i.e. estimated targets as returned by a tagger.</span>\n",
    "> <br/><span style=\"padding-left:20px;\"/><tt>references</tt>: a list of lists of reference labels, i.e. the ground truth/target values.</span>\n",
    "\n",
    "\n",
    "It works like this:\n",
    " \n",
    "    seqeval = evaluate.load('seqeval')\n",
    "    predictions = [['O', 'O', 'B-MISC', 'I-MISC', 'I-MISC', 'I-MISC', 'O'], ['B-PER', 'I-PER', 'O']]\n",
    "    references = [['O', 'O', 'O', 'B-MISC', 'I-MISC', 'I-MISC', 'O'], ['B-PER', 'I-PER', 'O']]\n",
    "    results = seqeval.compute(predictions=predictions, references=references)\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c33e754b-3cc8-4e2c-b37c-04c2b4d684da",
   "metadata": {},
   "source": [
    "# !pip install seqeval"
   ]
  },
  {
   "cell_type": "raw",
   "id": "dba4491c-3dcb-42ac-963d-d63b42e71589",
   "metadata": {},
   "source": [
    "!conda install seqeval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e9e81ac9-49ba-4237-9344-f4ab57d03b67",
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate\n",
    "\n",
    "metric = evaluate.load(\"seqeval\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5dc5b6b-6c9f-49e7-b86c-81740308647e",
   "metadata": {},
   "source": [
    "##### Quick example of `seqeval`\n",
    "\n",
    "* Take the NER tags very first training example as being truth.\n",
    "* Copy those labels and change the 3rd one from `B-INTJ` to O``, just for kicks\n",
    "* Now evaluate with `seqeval`, passing in your `predictions` and `references` (both as lists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b4d52c54-21bd-47c9-b41f-d4848e35b6ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labels: ['B-ADVP', 'O', 'B-INTJ', 'O', 'O', 'O', 'B-INTJ', 'O', 'O']\n"
     ]
    }
   ],
   "source": [
    "labels = raw_datasets[\"train\"][0][\"ner_tags\"]\n",
    "labels = [label_names[i] for i in labels]\n",
    "\n",
    "print(f\"labels: {labels}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7c38dce5-8c27-4377-992e-3bc86486b673",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predictions: ['B-ADVP', 'O', 'O', 'O', 'O', 'O', 'B-INTJ', 'O', 'O']\n"
     ]
    }
   ],
   "source": [
    "predictions = labels.copy()\n",
    "predictions[2] = \"O\"\n",
    "\n",
    "print(f\"predictions: {predictions}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ffbba189-d33a-4c8f-b079-9245b022c2a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ADVP': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0, 'number': 1},\n",
       " 'INTJ': {'precision': 1.0,\n",
       "  'recall': 0.5,\n",
       "  'f1': 0.6666666666666666,\n",
       "  'number': 2},\n",
       " 'overall_precision': 1.0,\n",
       " 'overall_recall': 0.6666666666666666,\n",
       " 'overall_f1': 0.8,\n",
       " 'overall_accuracy': 0.8888888888888888}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metric.compute(predictions=[predictions], references=[labels])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66c21721-9111-4c47-ae95-00197a4441b6",
   "metadata": {},
   "source": [
    "...\n",
    "\n",
    "> This `compute_metrics()` function first takes the argmax of the logits to convert them to predictions (as usual, the logits and the probabilities are in the same order, so we donâ€™t need to apply the softmax). Then we have to convert both labels and predictions from integers to strings. We remove all the values where the label is `-100`, then pass the results to the `metric.compute()` method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "910b5c33-bfb1-4ca8-920d-3e9887ccddbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def compute_metrics(eval_preds):\n",
    "    # unpack\n",
    "    logits, labels = eval_preds\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "\n",
    "    # Remove ignored index (special tokens) and convert to labels\n",
    "    true_labels = [\n",
    "        [label_names[l] for l in label if l != -100]\n",
    "        for label in labels\n",
    "    ]\n",
    "    \n",
    "    true_predictions = [\n",
    "        [label_names[p] for (p, l) in zip(prediction, label) if l != -100]\n",
    "        for prediction, label in zip(predictions, labels)\n",
    "    ]\n",
    "    \n",
    "    all_metrics = metric.compute(predictions=true_predictions, references=true_labels)\n",
    "    \n",
    "    return {\n",
    "        \"precision\": all_metrics[\"overall_precision\"],\n",
    "        \"recall\": all_metrics[\"overall_recall\"],\n",
    "        \"f1\": all_metrics[\"overall_f1\"],\n",
    "        \"accuracy\": all_metrics[\"overall_accuracy\"],\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5348ae63-8356-4c8f-af1a-a097ce1c6d4b",
   "metadata": {},
   "source": [
    "#### Defining the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c305ac2f-adb2-419a-a4a5-ebe0916e79ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['O', 'B-PER', 'I-PER', 'B-ORG', 'I-ORG', 'B-LOC', 'I-LOC', 'B-MISC', 'I-MISC']\n"
     ]
    }
   ],
   "source": [
    "# we need to reset label_names since we re-used that var for both the POS and CHUNKING bits\n",
    "label_names = ner_feature.feature.names\n",
    "\n",
    "print(label_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "19415d06-16e3-45c9-8076-ead1cf54abef",
   "metadata": {},
   "outputs": [],
   "source": [
    "id2label = {i: label for i, label in enumerate(label_names)}\n",
    "label2id = {v: k for k, v in id2label.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "480bf332-aba1-4473-abba-4ae668ab3233",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForTokenClassification\n",
    "\n",
    "model = AutoModelForTokenClassification.from_pretrained(\n",
    "    model_checkpoint,\n",
    "    id2label=id2label,\n",
    "    label2id=label2id,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "22eaacc3-a842-4e63-a565-3635dd9d3bbb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.config.num_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "689403be-3878-4de3-b1d7-2dc93d202f59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'O',\n",
       " 1: 'B-PER',\n",
       " 2: 'I-PER',\n",
       " 3: 'B-ORG',\n",
       " 4: 'I-ORG',\n",
       " 5: 'B-LOC',\n",
       " 6: 'I-LOC',\n",
       " 7: 'B-MISC',\n",
       " 8: 'I-MISC'}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id2label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eb7dc4a-8168-4c1a-b1e1-6268bcc9023b",
   "metadata": {},
   "source": [
    "#### Fine-tuning the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "cf84902f-926c-4ea4-ac99-1c53a0fe3abc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5391879163fa47e58b13e8eed2233f1c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "5e7b1c1f-4d37-4293-8e42-4fa08eb99499",
   "metadata": {},
   "source": [
    "huggingface-cli login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ea35a834-542f-49bd-8abb-4e14c3582c0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/learn-hf/lib/python3.9/site-packages/transformers/training_args.py:1594: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "from transformers import TrainingArguments\n",
    "\n",
    "args = TrainingArguments(\n",
    "    \"bert-finetuned-ner\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    "    push_to_hub=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feb565a2-e0c4-438b-9caf-b40e280c734c",
   "metadata": {},
   "source": [
    "    from transformers import Trainer\n",
    "\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=args,\n",
    "        train_dataset=tokenized_datasets[\"train\"],\n",
    "        eval_dataset=tokenized_datasets[\"validation\"],\n",
    "        data_collator=data_collator,\n",
    "        compute_metrics=compute_metrics,\n",
    "        tokenizer=tokenizer    # <<<<<< `tokenizer` is deprecated... Use `processing_class` instead\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e72bb99a-efcb-4649-84ad-b408d790a997",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Trainer\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=args,\n",
    "    train_dataset=tokenized_datasets[\"train\"],\n",
    "    eval_dataset=tokenized_datasets[\"validation\"],\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    "    processing_class=tokenizer,\n",
    ")\n",
    "#trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "1a998005-67ec-4f5b-85b3-aaff62b29e30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5268' max='5268' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5268/5268 09:50, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.077000</td>\n",
       "      <td>0.066341</td>\n",
       "      <td>0.901906</td>\n",
       "      <td>0.931505</td>\n",
       "      <td>0.916467</td>\n",
       "      <td>0.981559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.034100</td>\n",
       "      <td>0.064706</td>\n",
       "      <td>0.930236</td>\n",
       "      <td>0.946988</td>\n",
       "      <td>0.938537</td>\n",
       "      <td>0.985489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.021900</td>\n",
       "      <td>0.060179</td>\n",
       "      <td>0.936184</td>\n",
       "      <td>0.950522</td>\n",
       "      <td>0.943299</td>\n",
       "      <td>0.986740</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 9min 26s, sys: 11.2 s, total: 9min 37s\n",
      "Wall time: 9min 59s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=5268, training_loss=0.06637766964071704, metrics={'train_runtime': 591.1167, 'train_samples_per_second': 71.26, 'train_steps_per_second': 8.912, 'total_flos': 920771584279074.0, 'train_loss': 0.06637766964071704, 'epoch': 3.0})"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "07f4cb24-2ecc-4352-9cfc-629dcf7eb631",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/buruzaemon/bert-finetuned-ner/commit/1a7552c5569373f76d0c628990fcec510d1533b1', commit_message='Training complete', commit_description='', oid='1a7552c5569373f76d0c628990fcec510d1533b1', pr_url=None, repo_url=RepoUrl('https://huggingface.co/buruzaemon/bert-finetuned-ner', endpoint='https://huggingface.co', repo_type='model', repo_id='buruzaemon/bert-finetuned-ner'), pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.push_to_hub(commit_message=\"Training complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "677d231d-31e2-491f-ad63-3f0e97e8319f",
   "metadata": {},
   "source": [
    "### A custom training loop\n",
    "\n",
    "... and for your edification, here's how to do it the _hard way_..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbc89114-9c74-4005-a307-061cf25b299d",
   "metadata": {},
   "source": [
    "#### Preparing everything for training\n",
    "\n",
    "> First we need to build the `DataLoaders` from our datasets.\n",
    "> Weâ€™ll reuse our `data_collator` as a `collate_fn`\n",
    "> and shuffle the training set, but _not_ the validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e17ad8b7-dd9a-4809-b7d3-3571f1f8be8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "    tokenized_datasets[\"train\"],\n",
    "    shuffle=True,\n",
    "    collate_fn=data_collator,\n",
    "    batch_size=8,\n",
    ")\n",
    "\n",
    "eval_dataloader = DataLoader(\n",
    "    tokenized_datasets[\"validation\"], \n",
    "    collate_fn=data_collator, \n",
    "    batch_size=8\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b61ae54-4f03-4747-8b6d-91e078776247",
   "metadata": {},
   "source": [
    "> Next we reinstantiate our model, to make sure weâ€™re not continuing\n",
    "> the fine-tuning from before but starting from the BERT pretrained\n",
    "> model again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "697a93f9-6896-4197-b98d-de4b44734238",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForTokenClassification.from_pretrained(\n",
    "    model_checkpoint,\n",
    "    id2label=id2label,\n",
    "    label2id=label2id,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e0fb34d-3275-4e2b-a7b5-8bfaf9a0869c",
   "metadata": {},
   "source": [
    "> Then we will need an optimizer. Weâ€™ll use the classic [`AdamW`](https://pytorch.org/docs/stable/generated/torch.optim.AdamW.html),\n",
    "> which is like `Adam`, but with a fix in the way weight decay is applied\n",
    "\n",
    "Why?\n",
    "> In case you have larger models or when training on complex, high-dimensional data, it's better to choose `AdamW`\n",
    "> [citation/proof needed]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "b3ad5c05-22e9-46d2-ad8f-27ad8f2daba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import AdamW\n",
    "\n",
    "optimizer = AdamW(model.parameters(), lr=2e-5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11dde6e1-8ac2-4b0e-9f3f-f1fcadb73a83",
   "metadata": {},
   "source": [
    "> Once we have all those objects, we can send them to the `accelerator.prepare()` method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "fa4df244-0566-4a10-83c0-ecba3e5a1bc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from accelerate import Accelerator\n",
    "\n",
    "accelerator = Accelerator()\n",
    "model, optimizer, train_dataloader, eval_dataloader = accelerator.prepare(\n",
    "    model, optimizer, train_dataloader, eval_dataloader\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c7c52a9-28b6-4925-b28e-ca1a2217d355",
   "metadata": {},
   "source": [
    "> Now that we have sent our `train_dataloader` to accelerator.prepare(), we can use its length to compute the number of training steps. Remember that we should always do this after preparing the dataloader, as that method will change its length. We use a classic linear schedule from the learning rate to 0\n",
    "\n",
    "\n",
    "* [`transformers.get_scheduler`](https://huggingface.co/docs/transformers/main/en/main_classes/optimizer_schedules#transformers.get_scheduler): ... read up on optimizations..?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a68c5611-82f7-41cb-a9c8-6a5577bd0988",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import get_scheduler\n",
    "\n",
    "num_train_epochs = 3\n",
    "num_update_steps_per_epoch = len(train_dataloader)\n",
    "num_training_steps = num_train_epochs * num_update_steps_per_epoch\n",
    "\n",
    "lr_scheduler = get_scheduler(\n",
    "    \"linear\",\n",
    "    optimizer=optimizer,\n",
    "    num_warmup_steps=0,\n",
    "    num_training_steps=num_training_steps,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b29c205b-a1f2-42b2-9509-f4d47ed2ec4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'buruzaemon/bert-finetuned-ner-accelerate'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from huggingface_hub import Repository, get_full_repo_name\n",
    "\n",
    "model_name = \"bert-finetuned-ner-accelerate\"\n",
    "repo_name = get_full_repo_name(model_name)\n",
    "repo_name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f1d8607-5934-4790-9840-bacfd7b9f5f9",
   "metadata": {},
   "source": [
    "> FutureWarning: 'Repository' (from 'huggingface_hub.repository') is deprecated and will be removed from version '1.0'. Please prefer the http-based alternatives instead. Given its large adoption in legacy code, the complete removal is only planned on next major release.<p/>\n",
    "> For more details, please read https://huggingface.co/docs/huggingface_hub/concepts/git_vs_http."
   ]
  },
  {
   "cell_type": "raw",
   "id": "44cee6d4-2efe-45e1-bf90-833cee2ad051",
   "metadata": {},
   "source": [
    "output_dir = \"bert-finetuned-ner-accelerate\"\n",
    "\n",
    "repo = Repository(output_dir, clone_from=repo_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb4ce37f-99d3-49a9-b899-ca0e7c5bddcb",
   "metadata": {},
   "source": [
    "##### Using `huggingface_hub.HfApi`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "4be7f692-6499-4ee0-82ff-8bbf4ff5a7b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import HfApi\n",
    "\n",
    "output_dir = model_name\n",
    "\n",
    "api = HfApi()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d5463a4-a7fb-4871-9f08-b6a3cfdcfae3",
   "metadata": {},
   "source": [
    "#### Training loop\n",
    "\n",
    "> We are now ready to write the full training loop. To simplify its evaluation part,\n",
    "> we define this postprocess() function that takes predictions and labels and converts\n",
    "> them to lists of strings, like our metric object expects (c.f. `seqeval`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "c19173f1-e845-4ea8-a81a-73709c33ea1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def postprocess(predictions, labels):\n",
    "    predictions = predictions.detach().cpu().clone().numpy()\n",
    "    labels = labels.detach().cpu().clone().numpy()\n",
    "\n",
    "    # Remove ignored index (special tokens) and convert to labels\n",
    "    true_labels = [[label_names[l] for l in label if l != -100] for label in labels]\n",
    "    true_predictions = [\n",
    "        [label_names[p] for (p, l) in zip(prediction, label) if l != -100]\n",
    "        for prediction, label in zip(predictions, labels)\n",
    "    ]\n",
    "    return true_labels, true_predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b680da2-655a-4553-a615-41d42fc00f17",
   "metadata": {},
   "source": [
    "The training loop covers three sub-tasks:\n",
    "\n",
    "1. training\n",
    "2. evaluation\n",
    "3. save & upload\n",
    "\n",
    "\n",
    "\n",
    "> The training in itself, which is the classic iteration over the\n",
    "> `train_dataloader`, forward pass through the model, then backward\n",
    "> pass and optimizer step.\n",
    ">\n",
    "> The evaluation, in which there is a novelty after getting the outputs\n",
    "> of our model on a batch: since two processes may have padded the inputs\n",
    "> and labels to different shapes, we need to use [`accelerator.pad_across_processes()`](https://huggingface.co/docs/accelerate/package_reference/accelerator#accelerate.Accelerator.pad_across_processes)\n",
    "> to make the predictions and labels the same shape before calling the\n",
    "> [`gather()`](https://huggingface.co/docs/accelerate/package_reference/accelerator#accelerate.Accelerator.gather)\n",
    "> method. If we donâ€™t do this, the evaluation will either error out or hang forever.\n",
    "> Then we send the results to `metric.add_batch()` and call `metric.compute()` once\n",
    "> the evaluation loop is over.\n",
    ">\n",
    "> Saving and uploading, where we first save the model and the tokenizer, then call\n",
    "> [`repo.push_to_hub()`](https://huggingface.co/docs/diffusers/v0.32.2/en/api/pipelines/overview#diffusers.utils.PushToHubMixin.push_to_hub).\n",
    "> Notice that we use the argument `blocking=False` to tell the ðŸ¤— Hub library to\n",
    "> push in an asynchronous process. This way, training continues normally and this\n",
    "> (long) instruction is executed in the background\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "560ba705-45dc-4cfb-b7f5-b93313bfcc55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb17222734dd4521ab0004644e95632e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5268 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0: {'precision': 0.9347021204981488, 'recall': 0.9038242473555737, 'f1': 0.9190038884752213, 'accuracy': 0.9812798022016836}\n",
      "epoch 1: {'precision': 0.9404240996297543, 'recall': 0.918625678119349, 'f1': 0.9293970893970893, 'accuracy': 0.9833107670571614}\n",
      "epoch 2: {'precision': 0.9488387748232918, 'recall': 0.9292895994725564, 'f1': 0.9389624448330418, 'accuracy': 0.9858568316948254}\n"
     ]
    }
   ],
   "source": [
    "from tqdm.auto import tqdm\n",
    "import torch\n",
    "\n",
    "progress_bar = tqdm(range(num_training_steps))\n",
    "\n",
    "for epoch in range(num_train_epochs):\n",
    "    # Training\n",
    "    model.train()\n",
    "    for batch in train_dataloader:\n",
    "        outputs = model(**batch)\n",
    "        loss = outputs.loss\n",
    "        accelerator.backward(loss)\n",
    "\n",
    "        optimizer.step()\n",
    "        lr_scheduler.step()\n",
    "        optimizer.zero_grad()\n",
    "        progress_bar.update(1)\n",
    "\n",
    "    # Evaluation\n",
    "    model.eval()\n",
    "    for batch in eval_dataloader:\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**batch)\n",
    "\n",
    "        predictions = outputs.logits.argmax(dim=-1)\n",
    "        labels = batch[\"labels\"]\n",
    "\n",
    "        # Necessary to pad predictions and labels for being gathered\n",
    "        predictions = accelerator.pad_across_processes(predictions, dim=1, pad_index=-100)\n",
    "        labels = accelerator.pad_across_processes(labels, dim=1, pad_index=-100)\n",
    "\n",
    "        predictions_gathered = accelerator.gather(predictions)\n",
    "        labels_gathered = accelerator.gather(labels)\n",
    "\n",
    "        true_predictions, true_labels = postprocess(predictions_gathered, labels_gathered)\n",
    "        metric.add_batch(predictions=true_predictions, references=true_labels)\n",
    "\n",
    "    results = metric.compute()\n",
    "    print(\n",
    "        f\"epoch {epoch}:\",\n",
    "        {\n",
    "            key: results[f\"overall_{key}\"]\n",
    "            for key in [\"precision\", \"recall\", \"f1\", \"accuracy\"]\n",
    "        },\n",
    "    )\n",
    "\n",
    "    # Save and upload\n",
    "    accelerator.wait_for_everyone()\n",
    "    unwrapped_model = accelerator.unwrap_model(model)\n",
    "    unwrapped_model.save_pretrained(output_dir, save_function=accelerator.save)\n",
    "    if accelerator.is_main_process:\n",
    "        tokenizer.save_pretrained(output_dir)\n",
    "        #repo.push_to_hub(\n",
    "        #    commit_message=f\"Training in progress epoch {epoch}\", blocking=False\n",
    "        #)\n",
    "        future = api.upload_folder( # Upload in the background (non-blocking action)\n",
    "            repo_id=repo_name,\n",
    "            folder_path=output_dir,\n",
    "            run_as_future=True,\n",
    "            commit_message=f\"Training in progress epoch {epoch}\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "raw",
   "id": "9f2986a1-481f-4693-940f-374e7210968e",
   "metadata": {},
   "source": [
    "repo.push_to_hub(commit_message=\"Training complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "92c4c120-1a05-4169-bb8e-0322927942dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/buruzaemon/bert-finetuned-ner-accelerate/commit/9a13eacccccdc648b14184596e56c15e086530cf', commit_message='Training completed!', commit_description='', oid='9a13eacccccdc648b14184596e56c15e086530cf', pr_url=None, repo_url=RepoUrl('https://huggingface.co/buruzaemon/bert-finetuned-ner-accelerate', endpoint='https://huggingface.co', repo_type='model', repo_id='buruzaemon/bert-finetuned-ner-accelerate'), pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "api.upload_folder(\n",
    "    repo_id=repo_name,\n",
    "    folder_path=output_dir,\n",
    "    commit_message=\"Training completed!\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45ed3167-3390-4c9f-9bf0-9497afd59c7e",
   "metadata": {},
   "source": [
    "#### Using the fine-tuned model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "fc0e0cc9-164a-4525-9b23-d0835585395e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37f819a3762542d98ff6faa7e5df3119",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.01k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "053c0a45ef8a4d4282a38bb1576cedc7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/431M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75bb6ff6072c4420a5ae0d57edc813f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/1.22k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "090d5ffcad5347e98fc46a6a018ed58a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/213k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76d2c3491e4f4562b517558fe3c2560a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/669k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a634c47f3ffb40a08a93e31769f1df65",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/125 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# Replace this with your own checkpoint\n",
    "model_checkpoint = \"buruzaemon/bert-finetuned-ner-accelerate\"\n",
    "\n",
    "token_classifier = pipeline(\n",
    "    \"token-classification\", \n",
    "    model=model_checkpoint, \n",
    "    aggregation_strategy=\"simple\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "b0c3cfd5-f431-421b-b16e-128ca369a08d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'entity_group': 'PER',\n",
       "  'score': 0.96822476,\n",
       "  'word': 'Buruzaemon',\n",
       "  'start': 11,\n",
       "  'end': 21},\n",
       " {'entity_group': 'LOC',\n",
       "  'score': 0.9975211,\n",
       "  'word': 'Hokkaido',\n",
       "  'start': 44,\n",
       "  'end': 52}]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_classifier(\"My name is Buruzaemon and I like fishing in Hokkaido.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a178187-6651-4508-a573-1835fc97ae60",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
