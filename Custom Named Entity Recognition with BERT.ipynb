{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3a9e4a9f-02e0-48f8-858c-6d73cc5b81ce",
   "metadata": {},
   "source": [
    "##### Environment check\n",
    "\n",
    "Before we begin, let's just confirm our current environment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0a8813e6-a70c-464a-bfb5-a8abacd3e7c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Copy-and-paste the text below in your GitHub issue and FILL OUT the two last points.\n",
      "\n",
      "- `transformers` version: 4.49.0\n",
      "- Platform: Linux-5.10.0-33-cloud-amd64-x86_64-with-glibc2.31\n",
      "- Python version: 3.9.21\n",
      "- Huggingface_hub version: 0.28.1\n",
      "- Safetensors version: 0.5.2\n",
      "- Accelerate version: 1.3.0\n",
      "- Accelerate config: \tnot found\n",
      "- DeepSpeed version: not installed\n",
      "- PyTorch version (GPU?): 2.5.1 (True)\n",
      "- Tensorflow version (GPU?): not installed (NA)\n",
      "- Flax version (CPU?/GPU?/TPU?): not installed (NA)\n",
      "- Jax version: not installed\n",
      "- JaxLib version: not installed\n",
      "- Using distributed or parallel set-up in script?: <fill in>\n",
      "- Using GPU in script?: <fill in>\n",
      "- GPU type: Tesla T4\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!transformers-cli env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e7214b3d-8a04-4c46-aef8-586429d8f82c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "from torch import cuda\n",
    "\n",
    "device = 'cuda' if cuda.is_available() else 'cpu'\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7184992-e4c7-4bb1-b42f-d5398aa0ae2e",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46cc4328-f5a2-4dad-8241-6a72ad30a321",
   "metadata": {},
   "source": [
    "# Custom Named Entity Recognition with BERT\n",
    "\n",
    "From [here](https://colab.research.google.com/github/NielsRogge/Transformers-Tutorials/blob/master/BERT/Custom_Named_Entity_Recognition_with_BERT_only_first_wordpiece.ipynb#scrollTo=MyETdB-dkBsX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "afae518f-8c51-4150-ab05-4db9fa7d0920",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import BertTokenizerFast, BertConfig, BertForTokenClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "601a664b-55c1-4832-a817-42803e5c0800",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_checkpoint = 'bert-base-uncased'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4c26995-3f3d-4316-9e01-625624d73973",
   "metadata": {},
   "source": [
    "### Downloading and preprocessing the data"
   ]
  },
  {
   "cell_type": "raw",
   "id": "70a40754-fd9f-4a10-b056-2baf69512936",
   "metadata": {},
   "source": [
    "!curl -L -o ner-dataset.zip https://www.kaggle.com/api/v1/datasets/download/namanj27/ner-dataset"
   ]
  },
  {
   "cell_type": "raw",
   "id": "4d3b7742-acca-4b75-bdc5-7fa7c2d1f210",
   "metadata": {},
   "source": [
    "!ls -la"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a1ba7f15-b109-4939-8c89-6059db8d63be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Sentence #           Word  POS Tag\n",
      "0  Sentence: 1      Thousands  NNS   O\n",
      "1          NaN             of   IN   O\n",
      "2          NaN  demonstrators  NNS   O\n",
      "3          NaN           have  VBP   O\n",
      "4          NaN        marched  VBN   O\n",
      "(1048575, 4)\n"
     ]
    }
   ],
   "source": [
    "#data = pd.read_csv(\"ner_datasetreference.csv\", encoding='unicode_escape')\n",
    "data = pd.read_csv(\"ner-dataset.zip\", encoding='unicode_escape')\n",
    "\n",
    "print(data.head())\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6bc710e4-2df3-400b-9206-4757db713d36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sentence #      47959\n",
       "Word          1048565\n",
       "POS           1048575\n",
       "Tag           1048575\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "85696e59-39d4-4c5d-875e-5a28118a6155",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tags: 17\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Tag\n",
       "O        887908\n",
       "B-geo     37644\n",
       "B-tim     20333\n",
       "B-org     20143\n",
       "I-per     17251\n",
       "B-per     16990\n",
       "I-org     16784\n",
       "B-gpe     15870\n",
       "I-geo      7414\n",
       "I-tim      6528\n",
       "B-art       402\n",
       "B-eve       308\n",
       "I-art       297\n",
       "I-eve       253\n",
       "B-nat       201\n",
       "I-gpe       198\n",
       "I-nat        51\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Number of tags: {}\".format(len(data.Tag.unique())))\n",
    "frequencies = data.Tag.value_counts()\n",
    "frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b4f35a9a-6cfb-45fa-9913-958b8d40623e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('geo', 45058), ('org', 36927), ('per', 34241), ('tim', 26861), ('gpe', 16068), ('art', 699), ('eve', 561), ('nat', 252)]\n"
     ]
    }
   ],
   "source": [
    "tags = {}\n",
    "for tag, count in zip(frequencies.index, frequencies):\n",
    "    if tag != \"O\":\n",
    "        if tag[2:5] not in tags.keys():\n",
    "            tags[tag[2:5]] = count\n",
    "        else:\n",
    "            tags[tag[2:5]] += count\n",
    "    continue\n",
    "\n",
    "print(sorted(tags.items(), key=lambda x: x[1], reverse=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "135648fb-bfa4-4452-8df3-69931bf29838",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Sentence #           Word  POS Tag\n",
      "0  Sentence: 1      Thousands  NNS   O\n",
      "1          NaN             of   IN   O\n",
      "2          NaN  demonstrators  NNS   O\n",
      "3          NaN           have  VBP   O\n",
      "4          NaN        marched  VBN   O\n",
      "(1047063, 4)\n"
     ]
    }
   ],
   "source": [
    "entities_to_remove = [\"B-art\", \"I-art\", \"B-eve\", \"I-eve\", \"B-nat\", \"I-nat\"]\n",
    "data = data[~data.Tag.isin(entities_to_remove)]\n",
    "\n",
    "print(data.head())\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c464df72-fd5f-4d5f-a628-c45782e06122",
   "metadata": {},
   "source": [
    "> We create 2 dictionaries: one that maps individual tags to indices,\n",
    "> and one that maps indices to their individual tags. This is necessary in\n",
    "> order to create the labels (as computers work with numbers = indices,\n",
    "> rather than words = tags) - see further in this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "839d6ed4-c825-488c-8eca-46656ef74145",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'O': 0,\n",
       " 'B-geo': 1,\n",
       " 'B-gpe': 2,\n",
       " 'B-per': 3,\n",
       " 'I-geo': 4,\n",
       " 'B-org': 5,\n",
       " 'I-org': 6,\n",
       " 'B-tim': 7,\n",
       " 'I-per': 8,\n",
       " 'I-gpe': 9,\n",
       " 'I-tim': 10}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_to_ids = {k: v for v, k in enumerate(data.Tag.unique())}\n",
    "\n",
    "labels_to_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "907685a9-45ed-42d6-999c-12763776077e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'O',\n",
       " 1: 'B-geo',\n",
       " 2: 'B-gpe',\n",
       " 3: 'B-per',\n",
       " 4: 'I-geo',\n",
       " 5: 'B-org',\n",
       " 6: 'I-org',\n",
       " 7: 'B-tim',\n",
       " 8: 'I-per',\n",
       " 9: 'I-gpe',\n",
       " 10: 'I-tim'}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ids_to_labels = {v: k for v, k in enumerate(data.Tag.unique())}\n",
    "\n",
    "ids_to_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ecfde6e-87fb-4163-9175-de8a7e38a29e",
   "metadata": {},
   "source": [
    "N.B.\n",
    "\n",
    "\n",
    "> <span style=\"background-color:#9fff33;\">FutureWarning: `DataFrame.fillna` with 'method' is deprecated and will raise in a future version. Use `obj.ffill()` or `obj.bfill()` instead.</span>\n",
    "\n",
    "Please see [`pandas.DataFrame.ffill`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.ffill.html#pandas-dataframe-ffill)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f6a38270-cf8a-41a2-b41b-481ce97ea62d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before:     Sentence #           Word  POS Tag\n",
      "0  Sentence: 1      Thousands  NNS   O\n",
      "1          NaN             of   IN   O\n",
      "2          NaN  demonstrators  NNS   O\n",
      "3          NaN           have  VBP   O\n",
      "4          NaN        marched  VBN   O\n",
      "\n",
      "After:     Sentence #           Word  POS Tag\n",
      "0  Sentence: 1      Thousands  NNS   O\n",
      "1  Sentence: 1             of   IN   O\n",
      "2  Sentence: 1  demonstrators  NNS   O\n",
      "3  Sentence: 1           have  VBP   O\n",
      "4  Sentence: 1        marched  VBN   O\n"
     ]
    }
   ],
   "source": [
    "print(f\"Before: {data.head()}\")\n",
    "print()\n",
    "\n",
    "# pandas has a very handy \"forward fill\" function to fill missing values based on the last upper non-nan value\n",
    "#data = data.fillna(method='ffill')\n",
    "data = data.ffill()\n",
    "\n",
    "print(f\"After: {data.head()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "305624c8-a1e2-457f-9fb5-67cf243c7522",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Sentence #', 'Word', 'POS', 'Tag'], dtype='object')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18640220-6377-4adf-b3de-8a4f8c99268e",
   "metadata": {},
   "source": [
    "> Now, we have to ask ourself the question: what is a training example in the case of NER,\n",
    "> which is provided in a single forward pass? A training example is typically a sentence,\n",
    "> with corresponding IOB tags. Let's group the words and corresponding tags by `sentence`...\n",
    "\n",
    "Using some Pandas magic, we are going to first concatenate all of the `Word` column values grouped by `Sentence #`, delimited by a whsp char.\n",
    "\n",
    "We then do nearly the same for `Tag` columns values again grouped by `Sentence #`, but delimited by a comma char."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "82bdb0c9-1211-47fa-adce-df3e5d12bc0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Sentence #           Word  POS Tag  \\\n",
      "0  Sentence: 1      Thousands  NNS   O   \n",
      "1  Sentence: 1             of   IN   O   \n",
      "2  Sentence: 1  demonstrators  NNS   O   \n",
      "3  Sentence: 1           have  VBP   O   \n",
      "4  Sentence: 1        marched  VBN   O   \n",
      "\n",
      "                                            sentence  \\\n",
      "0  Thousands of demonstrators have marched throug...   \n",
      "1  Thousands of demonstrators have marched throug...   \n",
      "2  Thousands of demonstrators have marched throug...   \n",
      "3  Thousands of demonstrators have marched throug...   \n",
      "4  Thousands of demonstrators have marched throug...   \n",
      "\n",
      "                                         word_labels  \n",
      "0  O,O,O,O,O,O,B-geo,O,O,O,O,O,B-geo,O,O,O,O,O,B-...  \n",
      "1  O,O,O,O,O,O,B-geo,O,O,O,O,O,B-geo,O,O,O,O,O,B-...  \n",
      "2  O,O,O,O,O,O,B-geo,O,O,O,O,O,B-geo,O,O,O,O,O,B-...  \n",
      "3  O,O,O,O,O,O,B-geo,O,O,O,O,O,B-geo,O,O,O,O,O,B-...  \n",
      "4  O,O,O,O,O,O,B-geo,O,O,O,O,O,B-geo,O,O,O,O,O,B-...  \n",
      "CPU times: user 8.02 s, sys: 144 ms, total: 8.17 s\n",
      "Wall time: 8.17 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# let's create a new column called \"sentence\" which groups the words by sentence \n",
    "data['sentence'] = (\n",
    "    data[['Sentence #','Word','Tag']]\n",
    "        .groupby(['Sentence #'])['Word']\n",
    "            .transform(lambda x: ' '.join(x))\n",
    ")\n",
    "\n",
    "# let's also create a new column called \"word_labels\" which groups the tags by sentence \n",
    "data['word_labels'] = (\n",
    "    data[['Sentence #','Word','Tag']]\n",
    "        .groupby(['Sentence #'])['Tag']\n",
    "            .transform(lambda x: ','.join(x))\n",
    ")\n",
    "\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e667bde1-52b2-4b7e-b060-21abcc5dd986",
   "metadata": {},
   "source": [
    "> Let's only keep the \"sentence\" and \"word_labels\" columns, and drop duplicates:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "11041ec0-c423-49f8-8d56-ba32e783b271",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                            sentence  \\\n",
      "0  Thousands of demonstrators have marched throug...   \n",
      "1  Families of soldiers killed in the conflict jo...   \n",
      "2  They marched from the Houses of Parliament to ...   \n",
      "3  Police put the number of marchers at 10,000 wh...   \n",
      "4  The protest comes on the eve of the annual con...   \n",
      "\n",
      "                                         word_labels  \n",
      "0  O,O,O,O,O,O,B-geo,O,O,O,O,O,B-geo,O,O,O,O,O,B-...  \n",
      "1  O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,B-per,O,O,...  \n",
      "2                O,O,O,O,O,O,O,O,O,O,O,B-geo,I-geo,O  \n",
      "3                      O,O,O,O,O,O,O,O,O,O,O,O,O,O,O  \n",
      "4  O,O,O,O,O,O,O,O,O,O,O,B-geo,O,O,B-org,I-org,O,...  \n",
      "(47571, 2)\n"
     ]
    }
   ],
   "source": [
    "data = (\n",
    "    data[[\"sentence\", \"word_labels\"]]\n",
    "        .drop_duplicates()\n",
    "        .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "print(data.head())\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "17c65924-bbb6-4828-b6a3-9780e08a2fca",
   "metadata": {},
   "source": [
    "print(data.iloc[41].sentence)\n",
    "print(data.iloc[41].word_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2ed97766-db2a-41f6-8e81-0145770f9024",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bedfordshire B-gpe\n",
      "police O\n",
      "said O\n",
      "Tuesday B-tim\n",
      "that O\n",
      "Omar B-per\n",
      "Khayam I-per\n",
      "was O\n",
      "arrested O\n",
      "in O\n",
      "Bedford B-geo\n",
      "for O\n",
      "breaching O\n",
      "the O\n",
      "conditions O\n",
      "of O\n",
      "his O\n",
      "parole O\n",
      ". O\n"
     ]
    }
   ],
   "source": [
    "for w,l in zip(data.iloc[41].sentence.split(), data.iloc[41].word_labels.split(',')):\n",
    "    print(w,l)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67b839f4-4bbf-490a-9d2c-1aac8aa8adbc",
   "metadata": {},
   "source": [
    "### Preparing the dataset and dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c5447f6f-3443-401b-94e2-6bed717b0d42",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LEN = 128\n",
    "TRAIN_BATCH_SIZE = 4\n",
    "VALID_BATCH_SIZE = 2\n",
    "EPOCHS = 1\n",
    "LEARNING_RATE = 1e-05\n",
    "MAX_GRAD_NORM = 10\n",
    "\n",
    "tokenizer = BertTokenizerFast.from_pretrained(model_checkpoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a922263d-e153-491f-b408-32795e853882",
   "metadata": {},
   "source": [
    "#### Implement a PyTorch [`Dataset`](https://pytorch.org/docs/stable/data.html#dataset-types)\n",
    "\n",
    "> The most important argument of `DataLoader` constructor is `dataset`,\n",
    "> which indicates a dataset object from which to load data. PyTorch supports two different types of dataset:<br/>\n",
    "> * [Map-style](https://pytorch.org/docs/stable/data.html#map-style-datasets) datasets that implement the `__getitem__` and `__len__` protocols\n",
    "> * [Iterable-style](https://pytorch.org/docs/stable/data.html#iterable-style-datasets) datasets that implement the `__iter__` protocol\n",
    "\n",
    "Here, we implement a map-style PyTorch `torch.utils.data.Dataset` class that will transform examples of the given dataframe to PyTorch tensors.\n",
    "\n",
    "1. each sentence gets tokenized\n",
    "2. special tokens that BERT expects are added\n",
    "3. the token sequences are padded or truncated based on the max length of the model\n",
    "4. the attention mask is created\n",
    "5. labels are created based on the dictionary which we defined above.\n",
    "\n",
    "Word pieces that should be ignored have a label of `-100`, the default `ignore_index` of PyTorch's [`CrossEntropyLoss`](https://pytorch.org/docs/stable/generated/torch.nn.functional.cross_entropy.html#torch-nn-functional-cross-entropy)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "564defed-8334-4f68-b3de-af20ccc8e273",
   "metadata": {},
   "outputs": [],
   "source": [
    "class dataset(Dataset):\n",
    "    def __init__(self, dataframe, tokenizer, max_len):\n",
    "        self.len = len(dataframe)\n",
    "        self.data = dataframe\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # step 1: get the sentence and word labels \n",
    "        sentence = self.data.sentence[index].strip().split()  \n",
    "        word_labels = self.data.word_labels[index].split(\",\") \n",
    "\n",
    "        # step 2: use tokenizer to encode sentence (includes padding/truncation up to max length)\n",
    "        # BertTokenizerFast provides a handy \"return_offsets_mapping\" functionality for individual tokens\n",
    "        encoding = self.tokenizer(\n",
    "            sentence,\n",
    "            #is_pretokenized=True,\n",
    "            is_split_into_words=True,\n",
    "            return_offsets_mapping=True, \n",
    "            padding='max_length', \n",
    "            truncation=True, \n",
    "            max_length=self.max_len\n",
    "        )\n",
    "        \n",
    "        # step 3: create token labels only for first word pieces of each tokenized word\n",
    "        labels = [labels_to_ids[label] for label in word_labels] \n",
    "        # code based on https://huggingface.co/transformers/custom_datasets.html#tok-ner\n",
    "        # create an empty array of -100 of length max_length\n",
    "        encoded_labels = np.ones(len(encoding[\"offset_mapping\"]), dtype=int) * -100\n",
    "        \n",
    "        # set only labels whose first offset position is 0 and the second is not 0\n",
    "        i = 0\n",
    "        for idx, mapping in enumerate(encoding[\"offset_mapping\"]):\n",
    "            if mapping[0] == 0 and mapping[1] != 0:\n",
    "                # overwrite label\n",
    "                encoded_labels[idx] = labels[i]\n",
    "                i += 1\n",
    "\n",
    "        # step 4: turn everything into PyTorch tensors\n",
    "        item = {key: torch.as_tensor(val) for key, val in encoding.items()}\n",
    "        item['labels'] = torch.as_tensor(encoded_labels)\n",
    "\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39c48ebb-5dfd-4fda-b8d0-7284681c07d8",
   "metadata": {},
   "source": [
    "> Now, based on the class we defined above, we can create 2 datasets, one for training and one for testing. Let's use a 80/20 split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "08e9221d-7f01-4a00-96bc-91772b48fa52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FULL Dataset: (47571, 2)\n",
      "TRAIN Dataset: (38057, 2)\n",
      "TEST Dataset: (9514, 2)\n"
     ]
    }
   ],
   "source": [
    "train_size = 0.8\n",
    "train_dataset = data.sample(frac=train_size,random_state=200)\n",
    "test_dataset = data.drop(train_dataset.index).reset_index(drop=True)\n",
    "train_dataset = train_dataset.reset_index(drop=True)\n",
    "\n",
    "print(\"FULL Dataset: {}\".format(data.shape))\n",
    "print(\"TRAIN Dataset: {}\".format(train_dataset.shape))\n",
    "print(\"TEST Dataset: {}\".format(test_dataset.shape))\n",
    "\n",
    "training_set = dataset(train_dataset, tokenizer, MAX_LEN)\n",
    "testing_set = dataset(test_dataset, tokenizer, MAX_LEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "47752183-bd26-4b84-ac34-8e922f5647e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([  101, 23564, 21030,  2099,  4967,  2001,  9388,  1011,  6109,  2005,\n",
       "          2634,  1012,   102,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0]),\n",
       " 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " 'offset_mapping': tensor([[0, 0],\n",
       "         [0, 2],\n",
       "         [2, 5],\n",
       "         [5, 6],\n",
       "         [0, 4],\n",
       "         [0, 3],\n",
       "         [0, 3],\n",
       "         [3, 4],\n",
       "         [4, 6],\n",
       "         [0, 3],\n",
       "         [0, 5],\n",
       "         [0, 1],\n",
       "         [0, 0],\n",
       "         [0, 0],\n",
       "         [0, 0],\n",
       "         [0, 0],\n",
       "         [0, 0],\n",
       "         [0, 0],\n",
       "         [0, 0],\n",
       "         [0, 0],\n",
       "         [0, 0],\n",
       "         [0, 0],\n",
       "         [0, 0],\n",
       "         [0, 0],\n",
       "         [0, 0],\n",
       "         [0, 0],\n",
       "         [0, 0],\n",
       "         [0, 0],\n",
       "         [0, 0],\n",
       "         [0, 0],\n",
       "         [0, 0],\n",
       "         [0, 0],\n",
       "         [0, 0],\n",
       "         [0, 0],\n",
       "         [0, 0],\n",
       "         [0, 0],\n",
       "         [0, 0],\n",
       "         [0, 0],\n",
       "         [0, 0],\n",
       "         [0, 0],\n",
       "         [0, 0],\n",
       "         [0, 0],\n",
       "         [0, 0],\n",
       "         [0, 0],\n",
       "         [0, 0],\n",
       "         [0, 0],\n",
       "         [0, 0],\n",
       "         [0, 0],\n",
       "         [0, 0],\n",
       "         [0, 0],\n",
       "         [0, 0],\n",
       "         [0, 0],\n",
       "         [0, 0],\n",
       "         [0, 0],\n",
       "         [0, 0],\n",
       "         [0, 0],\n",
       "         [0, 0],\n",
       "         [0, 0],\n",
       "         [0, 0],\n",
       "         [0, 0],\n",
       "         [0, 0],\n",
       "         [0, 0],\n",
       "         [0, 0],\n",
       "         [0, 0],\n",
       "         [0, 0],\n",
       "         [0, 0],\n",
       "         [0, 0],\n",
       "         [0, 0],\n",
       "         [0, 0],\n",
       "         [0, 0],\n",
       "         [0, 0],\n",
       "         [0, 0],\n",
       "         [0, 0],\n",
       "         [0, 0],\n",
       "         [0, 0],\n",
       "         [0, 0],\n",
       "         [0, 0],\n",
       "         [0, 0],\n",
       "         [0, 0],\n",
       "         [0, 0],\n",
       "         [0, 0],\n",
       "         [0, 0],\n",
       "         [0, 0],\n",
       "         [0, 0],\n",
       "         [0, 0],\n",
       "         [0, 0],\n",
       "         [0, 0],\n",
       "         [0, 0],\n",
       "         [0, 0],\n",
       "         [0, 0],\n",
       "         [0, 0],\n",
       "         [0, 0],\n",
       "         [0, 0],\n",
       "         [0, 0],\n",
       "         [0, 0],\n",
       "         [0, 0],\n",
       "         [0, 0],\n",
       "         [0, 0],\n",
       "         [0, 0],\n",
       "         [0, 0],\n",
       "         [0, 0],\n",
       "         [0, 0],\n",
       "         [0, 0],\n",
       "         [0, 0],\n",
       "         [0, 0],\n",
       "         [0, 0],\n",
       "         [0, 0],\n",
       "         [0, 0],\n",
       "         [0, 0],\n",
       "         [0, 0],\n",
       "         [0, 0],\n",
       "         [0, 0],\n",
       "         [0, 0],\n",
       "         [0, 0],\n",
       "         [0, 0],\n",
       "         [0, 0],\n",
       "         [0, 0],\n",
       "         [0, 0],\n",
       "         [0, 0],\n",
       "         [0, 0],\n",
       "         [0, 0],\n",
       "         [0, 0],\n",
       "         [0, 0],\n",
       "         [0, 0],\n",
       "         [0, 0],\n",
       "         [0, 0],\n",
       "         [0, 0],\n",
       "         [0, 0]]),\n",
       " 'labels': tensor([-100,    3, -100, -100,    8,    0,    0, -100, -100,    0,    1,    0,\n",
       "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "         -100, -100, -100, -100, -100, -100, -100, -100])}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_set[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2f3976e1-68f8-478d-9120-89a66203bad6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CLS]       -100\n",
      "za          3\n",
      "##hee       -100\n",
      "##r         -100\n",
      "khan        8\n",
      "was         0\n",
      "mar         0\n",
      "-           -100\n",
      "93          -100\n",
      "for         0\n",
      "india       1\n",
      ".           0\n",
      "[SEP]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n",
      "[PAD]       -100\n"
     ]
    }
   ],
   "source": [
    "for token, label in zip(tokenizer.convert_ids_to_tokens(training_set[0][\"input_ids\"]), training_set[0][\"labels\"]):\n",
    "    print('{0:10}  {1}'.format(token, label))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f58d6c3-e569-46e5-a81d-5b4650d795f0",
   "metadata": {},
   "source": [
    "> Now, let's define the corresponding PyTorch dataloaders:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "050fdace-0d8b-4c90-a246-ba81f769a036",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_params = {\n",
    "    'batch_size': TRAIN_BATCH_SIZE,\n",
    "    'shuffle': True,\n",
    "    'num_workers': 0\n",
    "}\n",
    "\n",
    "test_params = {\n",
    "    'batch_size': VALID_BATCH_SIZE,\n",
    "    'shuffle': True,\n",
    "    'num_workers': 0\n",
    "}\n",
    "\n",
    "training_loader = DataLoader(training_set, **train_params)\n",
    "testing_loader = DataLoader(testing_set, **test_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "415f3df3-6eaf-45d6-a1ac-09bce84cd686",
   "metadata": {},
   "source": [
    "#### Defining the model\n",
    "\n",
    "> ... we define the model, [`BertForTokenClassification`](https://huggingface.co/docs/transformers/v4.49.0/en/model_doc/bert#transformers.BertForTokenClassification),\n",
    "> and load it with the pretrained weights of `bert-base-uncased`. The only thing we need to additionally specify\n",
    "> is the number of labels (as this will determine the architecture of the classification head)...\n",
    ">\n",
    "> ... only the base layers are initialized with the pretrained weights. The token classification head of top has\n",
    "> just randomly initialized weights, which we will train, together with the pretrained weights, using our labelled\n",
    "> dataset. This is also printed as a warning when you run the code cell below...\n",
    ">\n",
    "> (don't forget that) we move the model to the GPU..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "eadfb861-b9d1-46a3-b327-3f3b6620c48c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertForTokenClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSdpaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=11, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = BertForTokenClassification.from_pretrained(\n",
    "    model_checkpoint, \n",
    "    num_labels=len(labels_to_ids)\n",
    ")\n",
    "\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61e3b8db-f335-407d-a34e-6058820309d2",
   "metadata": {},
   "source": [
    "#### Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0a202c30-fde6-413c-9a9f-04d3e6779bac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.4655, device='cuda:0', grad_fn=<NllLossBackward0>)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = training_set[2]\n",
    "input_ids = inputs[\"input_ids\"].unsqueeze(0)\n",
    "attention_mask = inputs[\"attention_mask\"].unsqueeze(0)\n",
    "labels = inputs[\"labels\"].unsqueeze(0)\n",
    "\n",
    "input_ids = input_ids.to(device)\n",
    "attention_mask = attention_mask.to(device)\n",
    "labels = labels.to(device)\n",
    "\n",
    "outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "initial_loss = outputs[0]\n",
    "initial_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "389ec37a-8f2c-4859-8258-8e7f45700aa9",
   "metadata": {},
   "source": [
    "> This looks good. Let's also verify that the logits of the neural network have a shape of (`batch_size`, `sequence_length`, `num_labels`):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4feb0be2-2c72-4ffd-8424-8365c13f0575",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 128, 11])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tr_logits = outputs[1]\n",
    "tr_logits.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c5c6756-cadc-4d87-93ce-8ab9ade5caa8",
   "metadata": {},
   "source": [
    "> Next, we define the optimizer. Here, we are just going to use Adam with a default learning rate.\n",
    "> One can also decide to use more advanced ones such as AdamW (Adam with weight decay fix), which is\n",
    "> included in the Transformers repository, and a learning rate scheduler, but we are not going to do that here.\n",
    ">\n",
    "> _... and why not?_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5f4e52cf-5a7c-415a-8667-e0bf07a99f14",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(\n",
    "    params=model.parameters(), \n",
    "    lr=LEARNING_RATE\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df298661-80f2-446e-af41-8bbfeb56b121",
   "metadata": {},
   "source": [
    "> Now let's define a regular PyTorch training function. It is partly based on [a really good repository about multilingual NER](https://github.com/chambliss/Multilingual_NER/blob/master/python/utils/main_utils.py#L344)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2730558e-16ed-4475-b238-b5fd2eb2c90d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "    tr_loss, tr_accuracy = 0, 0\n",
    "    nb_tr_examples, nb_tr_steps = 0, 0\n",
    "    tr_preds, tr_labels = [], []\n",
    "    # put model in training mode\n",
    "    model.train()\n",
    "    \n",
    "    for idx, batch in enumerate(training_loader):\n",
    "        \n",
    "        ids = batch['input_ids'].to(device, dtype = torch.long)\n",
    "        mask = batch['attention_mask'].to(device, dtype = torch.long)\n",
    "        labels = batch['labels'].to(device, dtype = torch.long)\n",
    "\n",
    "        #loss, tr_logits = model(input_ids=ids, attention_mask=mask, labels=labels)\n",
    "        outputs = model(input_ids=ids, attention_mask=mask, labels=labels)\n",
    "        loss = outputs.loss\n",
    "        logits = outputs.logits\n",
    "        tr_loss += loss.item()\n",
    "\n",
    "        nb_tr_steps += 1\n",
    "        nb_tr_examples += labels.size(0)\n",
    "        \n",
    "        if idx % 100==0:\n",
    "            loss_step = tr_loss/nb_tr_steps\n",
    "            print(f\"Training loss per 100 training steps: {loss_step}\")\n",
    "           \n",
    "        # compute training accuracy\n",
    "        flattened_targets = labels.view(-1) # shape (batch_size * seq_len,)\n",
    "        active_logits = tr_logits.view(-1, model.num_labels) # shape (batch_size * seq_len, num_labels)\n",
    "        flattened_predictions = torch.argmax(active_logits, axis=1) # shape (batch_size * seq_len,)\n",
    "        \n",
    "        # only compute accuracy at active labels\n",
    "        active_accuracy = labels.view(-1) != -100 # shape (batch_size, seq_len)\n",
    "        #active_labels = torch.where(active_accuracy, labels.view(-1), torch.tensor(-100).type_as(labels))\n",
    "        \n",
    "        labels = torch.masked_select(flattened_targets, active_accuracy)\n",
    "        predictions = torch.masked_select(flattened_predictions, active_accuracy)\n",
    "        \n",
    "        tr_labels.extend(labels)\n",
    "        tr_preds.extend(predictions)\n",
    "\n",
    "        tmp_tr_accuracy = accuracy_score(labels.cpu().numpy(), predictions.cpu().numpy())\n",
    "        tr_accuracy += tmp_tr_accuracy\n",
    "    \n",
    "        # gradient clipping\n",
    "        torch.nn.utils.clip_grad_norm_(\n",
    "            parameters=model.parameters(), max_norm=MAX_GRAD_NORM\n",
    "        )\n",
    "        \n",
    "        # backward pass\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    epoch_loss = tr_loss / nb_tr_steps\n",
    "    tr_accuracy = tr_accuracy / nb_tr_steps\n",
    "    print(f\"Training loss epoch: {epoch_loss}\")\n",
    "    print(f\"Training accuracy epoch: {tr_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "384f9f5b-e00f-4f03-9099-b5a756390c69",
   "metadata": {},
   "source": [
    "... and we're off!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "dca12288-9fe9-4c38-90bb-06ddf15c5ce3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training epoch: 1\n",
      "Training loss per 100 training steps: 2.3968489170074463\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (512) must match the size of tensor b (128) at non-singleton dimension 0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "File \u001b[0;32m<timed exec>:3\u001b[0m\n",
      "Cell \u001b[0;32mIn[27], line 37\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(epoch)\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;66;03m#active_labels = torch.where(active_accuracy, labels.view(-1), torch.tensor(-100).type_as(labels))\u001b[39;00m\n\u001b[1;32m     36\u001b[0m labels \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmasked_select(flattened_targets, active_accuracy)\n\u001b[0;32m---> 37\u001b[0m predictions \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmasked_select\u001b[49m\u001b[43m(\u001b[49m\u001b[43mflattened_predictions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mactive_accuracy\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     39\u001b[0m tr_labels\u001b[38;5;241m.\u001b[39mextend(labels)\n\u001b[1;32m     40\u001b[0m tr_preds\u001b[38;5;241m.\u001b[39mextend(predictions)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (512) must match the size of tensor b (128) at non-singleton dimension 0"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    print(f\"Training epoch: {epoch + 1}\")\n",
    "    train(epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d045f8c8-0086-4558-b0b2-caea8f666541",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "805bb035-9e10-4c48-9014-6730a81a8bfa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6de7c813-7e9a-4e3b-b33e-9c7e03b25456",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
