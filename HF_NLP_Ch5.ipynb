{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c4a4d27b-9235-43fa-997c-697e72f24e06",
   "metadata": {},
   "source": [
    "# NLP Course\n",
    "\n",
    "Please see the [Hugging Face NLP Course page](https://huggingface.co/learn/nlp-course/chapter0/1?fw=pt)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0103742b-c355-4619-be05-ec7d0c61ad33",
   "metadata": {},
   "source": [
    "## 5. The ðŸ¤— Datasets library"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b4e4ff7-5fcf-49d9-9d64-0cfb2e8db0a2",
   "metadata": {},
   "source": [
    "### What if my dataset isnâ€™t on the Hub?"
   ]
  },
  {
   "cell_type": "raw",
   "id": "baf8a8ae-f2af-44ab-8a5f-8f7dda658c4f",
   "metadata": {},
   "source": [
    "!wget https://github.com/crux82/squad-it/raw/master/SQuAD_it-train.json.gz\n",
    "!wget https://github.com/crux82/squad-it/raw/master/SQuAD_it-test.json.gz"
   ]
  },
  {
   "cell_type": "raw",
   "id": "49e38fdf-eb01-4efd-846e-3d5a94b076e4",
   "metadata": {},
   "source": [
    "!gzip -dkv SQuAD_it-*.json.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5a054993-6e4a-47d7-a6e2-818a7ba39dc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 627300\n",
      "drwxr-xr-x 5 se_olliphant se_olliphant      4096 Feb  5 12:42 .\n",
      "drwxr-xr-x 3 se_olliphant se_olliphant      4096 Jan 31 06:42 ..\n",
      "drwxr-xr-x 2 se_olliphant se_olliphant      4096 Feb  4 07:27 .ipynb_checkpoints\n",
      "-rw-r--r-- 1 se_olliphant se_olliphant     14239 Jan 31 07:05 Ch2_p38.ipynb\n",
      "-rw-r--r-- 1 se_olliphant se_olliphant     22696 Feb  1 04:21 HF_NLP_Ch2.ipynb\n",
      "-rw-r--r-- 1 se_olliphant se_olliphant     49292 Feb  4 03:25 HF_NLP_Ch3.ipynb\n",
      "-rw-r--r-- 1 se_olliphant se_olliphant      5472 Feb  4 03:26 HF_NLP_Ch4.ipynb\n",
      "-rw-r--r-- 1 se_olliphant se_olliphant     29410 Feb  5 12:42 HF_NLP_Ch5.ipynb\n",
      "-rw-r--r-- 1 se_olliphant se_olliphant   8385528 Feb  4 06:25 SQuAD_it-test.json\n",
      "-rw-r--r-- 1 se_olliphant se_olliphant   1051245 Feb  4 06:25 SQuAD_it-test.json.gz\n",
      "-rw-r--r-- 1 se_olliphant se_olliphant  43605829 Feb  4 06:25 SQuAD_it-train.json\n",
      "-rw-r--r-- 1 se_olliphant se_olliphant   7725286 Feb  4 06:25 SQuAD_it-train.json.gz\n",
      "-rw-r--r-- 1 se_olliphant se_olliphant      2417 Feb  2 03:48 Untitled.ipynb\n",
      "drwxr-xr-x 5 se_olliphant se_olliphant      4096 Feb  5 12:39 drug-reviews\n",
      "-rw-r--r-- 1 se_olliphant se_olliphant 106288152 Feb  5 12:40 drug-reviews-test.jsonl\n",
      "-rw-r--r-- 1 se_olliphant se_olliphant 255839630 Feb  5 12:40 drug-reviews-train.jsonl\n",
      "-rw-r--r-- 1 se_olliphant se_olliphant  63913350 Feb  5 12:40 drug-reviews-validation.jsonl\n",
      "-rw-r--r-- 1 se_olliphant se_olliphant  28071166 Oct  2  2018 drugsComTest_raw.tsv\n",
      "-rw-r--r-- 1 se_olliphant se_olliphant  84289175 Oct  2  2018 drugsComTrain_raw.tsv\n",
      "-rw-r--r-- 1 se_olliphant se_olliphant  42989872 Feb  4 07:30 drugsCom_raw.zip\n",
      "-rw-r--r-- 1 se_olliphant se_olliphant     14948 Feb  1 01:40 environment.yml\n",
      "drwxr-xr-x 5 se_olliphant se_olliphant      4096 Feb  2 03:58 test-trainer\n"
     ]
    }
   ],
   "source": [
    "!ls -la"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34396fb9-434a-4368-9b03-1b21ff9835fb",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3562cce4-8171-4355-89c0-ac36f491405e",
   "metadata": {},
   "source": [
    "##### When there are separate datafiles for train, test, etc.\n",
    "\n",
    "Loading the local datafile `SQuAD_it-train.json` (after `gunzip`ing). Also, we know that the `data` JSON object (an array) contains the data examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "087fdb6b-cd1b-49e9-a823-014b2e57a860",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"data\": [\n",
      "        {\n",
      "            \"title\": \"Terremoto del Sichuan del 2008\",\n",
      "            \"paragraphs\": [\n",
      "                {\n",
      "                    \"context\": \"Il terremoto del Sichuan del 2008 o il terremoto del Gran Sichuan, misurato a 8.0 Ms e 7.9 Mw, e si Ã¨ verificato alle 02:28:01 PM China Standard Time all' epicentro (06:28:01 UTC) il 12 maggio nella provincia del Sichuan, ha ucciso 69.197 persone e lasciato 18.222 dispersi.\",\n",
      "                    \"qas\": [\n",
      "                        {\n",
      "                            \"id\": \"56cdca7862d2951400fa6826\",\n",
      "                            \"answers\": [\n",
      "                                {\n",
      "                                    \"text\": \"2008\",\n",
      "                                    \"answer_start\": 29\n",
      "                                }\n",
      "                            ],\n",
      "                            \"question\": \"In quale anno si Ã¨ verificato il terremoto nel Sichuan?\"\n",
      "                        },\n",
      "                        {\n",
      "                            \"id\": \"56cdca7862d2951400fa6828\",\n"
     ]
    }
   ],
   "source": [
    "!head -n 20 SQuAD_it-train.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "16149f38-7bfc-4a5e-85ab-74549823cf7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['title', 'paragraphs'],\n",
       "        num_rows: 442\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "squad_it_dataset = load_dataset(\"json\", data_files=\"SQuAD_it-train.json\", field=\"data\")\n",
    "squad_it_dataset"
   ]
  },
  {
   "cell_type": "raw",
   "id": "0c8b967c-7b22-431e-8263-0cacfd5713a1",
   "metadata": {},
   "source": [
    "squad_it_dataset[\"train\"][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22d7a311-da32-45f1-8466-55639edc818d",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f47acaa-71c9-479e-b5bf-e65a93b59a44",
   "metadata": {},
   "source": [
    "##### Using a `dict` where the keys are the dataset split names; and the values are the local `gunzip`ped datafiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5f04d714-0435-48f5-91a8-947087119ddd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['title', 'paragraphs'],\n",
       "        num_rows: 442\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['title', 'paragraphs'],\n",
       "        num_rows: 48\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_files = {\n",
    "    \"train\": \"SQuAD_it-train.json\", \n",
    "    \"test\": \"SQuAD_it-test.json\"\n",
    "}\n",
    "\n",
    "squad_it_dataset = load_dataset(\"json\", data_files=data_files, field=\"data\")\n",
    "squad_it_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79ace2ce-faef-458d-a6d5-a3bf311e5c76",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ca8b9c0-7f6a-4fd3-ad1c-49c51a8fb07e",
   "metadata": {},
   "source": [
    "##### Using a `dict` where the keys are the dataset split names; and the values are the download `gz` archive files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d16bcbdd-aa2a-4869-bc3e-3db01f964050",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['title', 'paragraphs'],\n",
       "        num_rows: 442\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['title', 'paragraphs'],\n",
       "        num_rows: 48\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_files = {\n",
    "    \"train\": \"SQuAD_it-train.json.gz\", \n",
    "    \"test\": \"SQuAD_it-test.json.gz\"\n",
    "}\n",
    "\n",
    "squad_it_dataset = load_dataset(\"json\", data_files=data_files, field=\"data\")\n",
    "squad_it_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44af157f-cb6f-491e-804c-081cb8affaf1",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b7e0bd6-1e77-4b39-876e-39934427e57c",
   "metadata": {},
   "source": [
    "##### Using a `dict` where the keys are the dataset split names; and the values are the URLs for the target data archive files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8e2c2f55-17f8-43e4-a114-e411ed681900",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['title', 'paragraphs'],\n",
       "        num_rows: 442\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['title', 'paragraphs'],\n",
       "        num_rows: 48\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_url = \"https://github.com/crux82/squad-it/raw/master/\"\n",
    "\n",
    "data_files = {\n",
    "    \"train\": f\"{base_url}SQuAD_it-train.json.gz\",\n",
    "    \"test\":  f\"{base_url}SQuAD_it-test.json.gz\",\n",
    "}\n",
    "\n",
    "squad_it_dataset = load_dataset(\"json\", data_files=data_files, field=\"data\")\n",
    "squad_it_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0cf08bd-0582-4488-8467-a94c6c770fed",
   "metadata": {},
   "source": [
    "### Time to slice and dice"
   ]
  },
  {
   "cell_type": "raw",
   "id": "158300e3-9dff-4af8-8371-85a64ab72312",
   "metadata": {},
   "source": [
    "!wget \"https://archive.ics.uci.edu/ml/machine-learning-databases/00462/drugsCom_raw.zip\"\n",
    "!unzip drugsCom_raw.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "93a983a4-9148-4723-905e-83951df20c3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 627300\n",
      "drwxr-xr-x 5 se_olliphant se_olliphant      4096 Feb  5 12:42 .\n",
      "drwxr-xr-x 3 se_olliphant se_olliphant      4096 Jan 31 06:42 ..\n",
      "drwxr-xr-x 2 se_olliphant se_olliphant      4096 Feb  4 07:27 .ipynb_checkpoints\n",
      "-rw-r--r-- 1 se_olliphant se_olliphant     14239 Jan 31 07:05 Ch2_p38.ipynb\n",
      "-rw-r--r-- 1 se_olliphant se_olliphant     22696 Feb  1 04:21 HF_NLP_Ch2.ipynb\n",
      "-rw-r--r-- 1 se_olliphant se_olliphant     49292 Feb  4 03:25 HF_NLP_Ch3.ipynb\n",
      "-rw-r--r-- 1 se_olliphant se_olliphant      5472 Feb  4 03:26 HF_NLP_Ch4.ipynb\n",
      "-rw-r--r-- 1 se_olliphant se_olliphant     29410 Feb  5 12:42 HF_NLP_Ch5.ipynb\n",
      "-rw-r--r-- 1 se_olliphant se_olliphant   8385528 Feb  4 06:25 SQuAD_it-test.json\n",
      "-rw-r--r-- 1 se_olliphant se_olliphant   1051245 Feb  4 06:25 SQuAD_it-test.json.gz\n",
      "-rw-r--r-- 1 se_olliphant se_olliphant  43605829 Feb  4 06:25 SQuAD_it-train.json\n",
      "-rw-r--r-- 1 se_olliphant se_olliphant   7725286 Feb  4 06:25 SQuAD_it-train.json.gz\n",
      "-rw-r--r-- 1 se_olliphant se_olliphant      2417 Feb  2 03:48 Untitled.ipynb\n",
      "drwxr-xr-x 5 se_olliphant se_olliphant      4096 Feb  5 12:39 drug-reviews\n",
      "-rw-r--r-- 1 se_olliphant se_olliphant 106288152 Feb  5 12:40 drug-reviews-test.jsonl\n",
      "-rw-r--r-- 1 se_olliphant se_olliphant 255839630 Feb  5 12:40 drug-reviews-train.jsonl\n",
      "-rw-r--r-- 1 se_olliphant se_olliphant  63913350 Feb  5 12:40 drug-reviews-validation.jsonl\n",
      "-rw-r--r-- 1 se_olliphant se_olliphant  28071166 Oct  2  2018 drugsComTest_raw.tsv\n",
      "-rw-r--r-- 1 se_olliphant se_olliphant  84289175 Oct  2  2018 drugsComTrain_raw.tsv\n",
      "-rw-r--r-- 1 se_olliphant se_olliphant  42989872 Feb  4 07:30 drugsCom_raw.zip\n",
      "-rw-r--r-- 1 se_olliphant se_olliphant     14948 Feb  1 01:40 environment.yml\n",
      "drwxr-xr-x 5 se_olliphant se_olliphant      4096 Feb  2 03:58 test-trainer\n"
     ]
    }
   ],
   "source": [
    "!ls -la"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a2c56013-4c8f-4337-ac3f-eb8bb548c007",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['Unnamed: 0', 'drugName', 'condition', 'review', 'rating', 'date', 'usefulCount'],\n",
       "        num_rows: 161297\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['Unnamed: 0', 'drugName', 'condition', 'review', 'rating', 'date', 'usefulCount'],\n",
       "        num_rows: 53766\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "data_files = {\n",
    "    \"train\": \"drugsComTrain_raw.tsv\", \n",
    "    \"test\": \"drugsComTest_raw.tsv\"\n",
    "}\n",
    "\n",
    "# \\t is the tab character in Python\n",
    "drug_dataset = load_dataset(\"csv\", data_files=data_files, delimiter=\"\\t\")\n",
    "drug_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8f0a0194-5208-4828-a588-edaeb4a3fdd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Unnamed: 0': [87571, 178045, 80482],\n",
       " 'drugName': ['Naproxen', 'Duloxetine', 'Mobic'],\n",
       " 'condition': ['Gout, Acute', 'ibromyalgia', 'Inflammatory Conditions'],\n",
       " 'review': ['\"like the previous person mention, I&#039;m a strong believer of aleve, it works faster for my gout than the prescription meds I take. No more going to the doctor for refills.....Aleve works!\"',\n",
       "  '\"I have taken Cymbalta for about a year and a half for fibromyalgia pain. It is great\\r\\nas a pain reducer and an anti-depressant, however, the side effects outweighed \\r\\nany benefit I got from it. I had trouble with restlessness, being tired constantly,\\r\\ndizziness, dry mouth, numbness and tingling in my feet, and horrible sweating. I am\\r\\nbeing weaned off of it now. Went from 60 mg to 30mg and now to 15 mg. I will be\\r\\noff completely in about a week. The fibro pain is coming back, but I would rather deal with it than the side effects.\"',\n",
       "  '\"I have been taking Mobic for over a year with no side effects other than an elevated blood pressure.  I had severe knee and ankle pain which completely went away after taking Mobic.  I attempted to stop the medication however pain returned after a few days.\"'],\n",
       " 'rating': [9.0, 3.0, 10.0],\n",
       " 'date': ['September 2, 2015', 'November 7, 2011', 'June 5, 2013'],\n",
       " 'usefulCount': [36, 13, 128]}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "drug_sample = drug_dataset[\"train\"].shuffle(seed=42).select(range(1000))\n",
    "# Peek at the first few examples\n",
    "drug_sample[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8ee8333-d7e7-429f-81ef-71334f8b73cf",
   "metadata": {},
   "source": [
    "> * The Unnamed: 0 column looks suspiciously like an anonymized ID for each patient.<br/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a34c4214-2d2d-4cdb-973d-e2a72d5e7502",
   "metadata": {},
   "outputs": [],
   "source": [
    "for split in drug_dataset.keys():\n",
    "    assert len(drug_dataset[split]) == len(drug_dataset[split].unique(\"Unnamed: 0\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "186ad5d1-b80e-41ca-915e-acd9b12ec02b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['patient_id', 'drugName', 'condition', 'review', 'rating', 'date', 'usefulCount'],\n",
       "        num_rows: 161297\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['patient_id', 'drugName', 'condition', 'review', 'rating', 'date', 'usefulCount'],\n",
       "        num_rows: 53766\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "drug_dataset = drug_dataset.rename_column(\n",
    "    original_column_name=\"Unnamed: 0\", new_column_name=\"patient_id\"\n",
    ")\n",
    "\n",
    "drug_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3c872519-97ab-4bbe-a351-eb6859d14533",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on method unique in module datasets.arrow_dataset:\n",
      "\n",
      "unique(column: str) -> List method of datasets.arrow_dataset.Dataset instance\n",
      "    Return a list of the unique elements in a column.\n",
      "    \n",
      "    This is implemented in the low-level backend and as such, very fast.\n",
      "    \n",
      "    Args:\n",
      "        column (`str`):\n",
      "            Column name (list all the column names with [`~datasets.Dataset.column_names`]).\n",
      "    \n",
      "    Returns:\n",
      "        `list`: List of unique elements in the given column.\n",
      "    \n",
      "    Example:\n",
      "    \n",
      "    ```py\n",
      "    >>> from datasets import load_dataset\n",
      "    >>> ds = load_dataset(\"rotten_tomatoes\", split=\"validation\")\n",
      "    >>> ds.unique('label')\n",
      "    [1, 0]\n",
      "    ```\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(drug_dataset[\"train\"].unique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6fac804d-e7d9-480b-8908-f6467e3c5c0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after filtering out rows where drugName or condition are empty:\n",
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['patient_id', 'drugName', 'condition', 'review', 'rating', 'date', 'usefulCount'],\n",
      "        num_rows: 160398\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['patient_id', 'drugName', 'condition', 'review', 'rating', 'date', 'usefulCount'],\n",
      "        num_rows: 53471\n",
      "    })\n",
      "})\n",
      "train, unique drug names: 3431\n",
      "train, unique conditions: 884\n",
      "\n",
      "test, unique drug names: 2635\n",
      "test, unique conditions: 708\n"
     ]
    }
   ],
   "source": [
    "drug_dataset = drug_dataset.filter(lambda r: r['drugName'] is not None and len(r['drugName'].strip()) > 0)\n",
    "drug_dataset = drug_dataset.filter(lambda r: r['condition'] is not None and len(r['drugName'].strip()) > 0)\n",
    "\n",
    "print(f\"after filtering out rows where drugName or condition are empty:\\n{drug_dataset}\")\n",
    "\n",
    "# train\n",
    "drug_names = [\n",
    "    n.lower() \n",
    "    for n in drug_dataset['train'].unique('drugName')\n",
    "]\n",
    "conditions = [\n",
    "    n.lower() \n",
    "    for n in drug_dataset['train'].unique('condition')\n",
    "]\n",
    "\n",
    "print(f\"train, unique drug names: {len(drug_names)}\")\n",
    "print(f\"train, unique conditions: {len(conditions)}\")\n",
    "\n",
    "print()\n",
    "\n",
    "# test\n",
    "drug_names = [\n",
    "    n.lower() \n",
    "    for n in drug_dataset['test'].unique('drugName')\n",
    "]\n",
    "conditions = [\n",
    "    n.lower() \n",
    "    for n in drug_dataset['test'].unique('condition')\n",
    "]\n",
    "\n",
    "print(f\"test, unique drug names: {len(drug_names)}\")\n",
    "print(f\"test, unique conditions: {len(conditions)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3daa54dd-1915-4232-88e9-98ee396e8120",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeb32857-a315-424c-8b34-427942efec7f",
   "metadata": {},
   "source": [
    "> * The condition column includes a mix of uppercase and lowercase labels.<br/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cd121311-c0e7-48d5-9da1-2a8d9cb753fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lowercase_condition(example):\n",
    "    return {\"condition\": example[\"condition\"].lower()}\n",
    "\n",
    "drug_dataset = drug_dataset.map(lowercase_condition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5ade5213-4b8f-4d3d-bae9-eb7b8b6b0d3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['left ventricular dysfunction', 'adhd', 'birth control']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check that lowercasing worked\n",
    "drug_dataset[\"train\"][\"condition\"][:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd9c80fb-beb4-4fed-b466-75ab84d18edc",
   "metadata": {},
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5ebce855-6d7e-4e7d-9ad3-ad72833a4c8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_review_length(example):\n",
    "    return {\"review_length\": len(example[\"review\"].split())}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cca4f5b5-0ccb-4200-ae29-261cacc0058a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'patient_id': 206461,\n",
       " 'drugName': 'Valsartan',\n",
       " 'condition': 'left ventricular dysfunction',\n",
       " 'review': '\"It has no side effect, I take it in combination of Bystolic 5 Mg and Fish Oil\"',\n",
       " 'rating': 9.0,\n",
       " 'date': 'May 20, 2012',\n",
       " 'usefulCount': 27,\n",
       " 'review_length': 17}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "drug_dataset = drug_dataset.map(compute_review_length)\n",
    "\n",
    "# Inspect the first training example\n",
    "drug_dataset[\"train\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ef822238-2001-4b6e-9c39-c1daafd1616e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'patient_id': [111469, 13653, 53602],\n",
       " 'drugName': ['Ledipasvir / sofosbuvir',\n",
       "  'Amphetamine / dextroamphetamine',\n",
       "  'Alesse'],\n",
       " 'condition': ['hepatitis c', 'adhd', 'birth control'],\n",
       " 'review': ['\"Headache\"', '\"Great\"', '\"Awesome\"'],\n",
       " 'rating': [10.0, 10.0, 10.0],\n",
       " 'date': ['February 3, 2015', 'October 20, 2009', 'November 23, 2015'],\n",
       " 'usefulCount': [41, 3, 0],\n",
       " 'review_length': [1, 1, 1]}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "drug_dataset[\"train\"].sort(\"review_length\")[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9350e9c0-ae62-4377-b70a-fe4cc3311891",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train': 138514, 'test': 46108}\n"
     ]
    }
   ],
   "source": [
    "drug_dataset = drug_dataset.filter(lambda x: x[\"review_length\"] > 30)\n",
    "\n",
    "print(drug_dataset.num_rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08e07492-2feb-40d4-88cb-1fbff9c54397",
   "metadata": {},
   "source": [
    "> * The reviews are of varying length and contain a mix of Python line separators (\\r\\n) as well as HTML character codes like &\\#039;."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "926a4e0d-e39c-4eab-9706-8e9a785c3eee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on method sort in module datasets.dataset_dict:\n",
      "\n",
      "sort(column_names: Union[str, Sequence[str]], reverse: Union[bool, Sequence[bool]] = False, null_placement: str = 'at_end', keep_in_memory: bool = False, load_from_cache_file: Optional[bool] = None, indices_cache_file_names: Optional[Dict[str, Optional[str]]] = None, writer_batch_size: Optional[int] = 1000) -> 'DatasetDict' method of datasets.dataset_dict.DatasetDict instance\n",
      "    Create a new dataset sorted according to a single or multiple columns.\n",
      "    \n",
      "    Args:\n",
      "        column_names (`Union[str, Sequence[str]]`):\n",
      "            Column name(s) to sort by.\n",
      "        reverse (`Union[bool, Sequence[bool]]`, defaults to `False`):\n",
      "            If `True`, sort by descending order rather than ascending. If a single bool is provided,\n",
      "            the value is applied to the sorting of all column names. Otherwise a list of bools with the\n",
      "            same length and order as column_names must be provided.\n",
      "        null_placement (`str`, defaults to `at_end`):\n",
      "            Put `None` values at the beginning if `at_start` or `first` or at the end if `at_end` or `last`\n",
      "        keep_in_memory (`bool`, defaults to `False`):\n",
      "            Keep the sorted indices in memory instead of writing it to a cache file.\n",
      "        load_from_cache_file (`Optional[bool]`, defaults to `True` if caching is enabled):\n",
      "            If a cache file storing the sorted indices\n",
      "            can be identified, use it instead of recomputing.\n",
      "        indices_cache_file_names (`[Dict[str, str]]`, *optional*, defaults to `None`):\n",
      "            Provide the name of a path for the cache file. It is used to store the\n",
      "            indices mapping instead of the automatically generated cache file name.\n",
      "            You have to provide one `cache_file_name` per dataset in the dataset dictionary.\n",
      "        writer_batch_size (`int`, defaults to `1000`):\n",
      "            Number of rows per write operation for the cache file writer.\n",
      "            Higher value gives smaller cache files, lower value consume less temporary memory.\n",
      "    \n",
      "    Example:\n",
      "    \n",
      "    ```py\n",
      "    >>> from datasets import load_dataset\n",
      "    >>> ds = load_dataset('rotten_tomatoes')\n",
      "    >>> ds['train']['label'][:10]\n",
      "    [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "    >>> sorted_ds = ds.sort('label')\n",
      "    >>> sorted_ds['train']['label'][:10]\n",
      "    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "    >>> another_sorted_ds = ds.sort(['label', 'text'], reverse=[True, False])\n",
      "    >>> another_sorted_ds['train']['label'][:10]\n",
      "    [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "    ```\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(drug_dataset.sort)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9a0ff856-91a1-43b5-b0f6-df3c406fbe36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'patient_id': [121004, 181160, 216072],\n",
       " 'drugName': ['Venlafaxine', 'Prozac', 'Copper'],\n",
       " 'condition': ['migraine', 'obsessive compulsive disorde', 'birth control'],\n",
       " 'review': ['\"Two and a half months ago I was prescribed Venlafaxine to help prevent chronic migraines.\\r\\nIt did help the migraines (reduced them by almost half), but with it came a host of side effects that were far worse than the problem I was trying to get rid of.\\r\\nHaving now come off of the stuff, I would not recommend anyone ever use Venlafaxine unless they suffer from extreme / suicidal depression. I mean extreme in the most emphatic sense of the word. \\r\\nBefore trying Venlafaxine, I was a writer. While on Venlafaxine, I could barely write or speak or communicate at all. More than that, I just didn&#039;t want to. Not normal for a usually outgoing extrovert.\\r\\nNow, I&#039;m beginning to write again - but my ability to speak and converse with others has deteriorated by about 95%. Writing these words is taking forever; keeping up in conversation with even one person is impossible, and I barely see the point of trying either. On Venlafaxine, words pretty much left me - my conversational vocabulary  was whittled down to the following:\\r\\n&quot;Mmm&quot; for yes; a sharp and clipped &quot;Mm&quot; for &quot;No&quot;\\r\\n&quot;Okay.&quot;\\r\\n&quot;Really?&quot;\\r\\n&quot;Oh right.&quot;\\r\\n&quot;Cool.&quot;\\r\\n&quot;That sucks&quot;\\r\\nAt the moment, I&#039;m a week into withdrawal, and I have to try extremely hard just to make the most mundane small talk. Last night I went to a party with some close friends, cheesy &#039;90s music, and a barbecue. About half of them are academics, and I couldn&#039;t keep up with conversations I normally would be able to; the other half like to dance and party, but I felt glued to my seat (as well as practically mute) and eventually walked off and found a quiet sofa to lie down on.\\r\\nI have never felt so isolated and lonely in my life. Thanks Venlafaxine.\\r\\nIf you consider yourself a social, creative, and curious person, DO NOT TAKE EVEN ONE DOSE OF VENLAFAXINE. Unless of course you are extremely extremely depressed. I&#039;ve suffered from depression in the past, but only mildly. Venlafaxine has shown me what true depression feels like.\\r\\nAs for the other side effects:\\r\\n- About two days&#039; worth of total joyful euphoria during the first 48 hours of taking Venlafaxine. Anxiety of all kinds evaporated. This felt amazing - although I can&#039;t remember what it felt like now. At the time, this extremely brief effect was powerful enough to make me feel that pushing on with Venlafaxine would be a Good Idea.\\r\\n- After that, I started feeling very sleepy. All the time. I slept more. No euphoria; more anxiety.\\r\\n- A week later, the night sweats started. My room was pretty cold (it was only spring in the UK), but I sweated more than I ever have on any tropical holiday. This meant that despite being extremely sleepy, I couldn&#039;t sleep.\\r\\nSince the side effects were supposed to wear off after six weeks or so, I stuck with Venlafaxine for six weeks. Over that time I became so sleep deprived that I lived in a state of permanent exhaustion.\\r\\nEnter the writer&#039;s worst enemy: Brain fog. I spent entire days so braindead that the most challenging thing I could manage was staring blankly at a wall - or lifting my phone to read text messages and attempt to learn something from articles about Venlafaxine. I&#039;ve read the same articles countless times, but nothing sank in; every time I read the same article it felt like I was reading it for the first time. I recognised the layout and design of each webpage, and that way I was able to realise I&#039;d read it before, but the actual text went in one eye and out the other.\\r\\nIn conversation, I had a brain like a sieve. Words went in one ear and out the other. Normally, I could pump out a lot of writing on a regular basis; on Venlafaxine, I wrote a small and frankly pitiful handful of short and uninspired pieces, and that was it. If you love being productive and creative, do not go near Venlafaxine.\\r\\nThe above was my life for six weeks - and that was enough. I did see family and friends while on Venlafaxine, but I constantly forgot what was going on and must have seemed scatterbrained or borderline retarded at times. Although I did explain to people what was going on with my medication, it just seemed to make people uncomfortable - and I&#039;ve now become the butt of a lot of jokes relating to my consistent uselessness at everything from chatting to party games and my inability to work or do anything productive. Someone even compared me to Lenny from Of Mice And Men and asked when my family were going to take me into the back garden and shoot me in the head rather than continue to care for me. All of this contributed to the worst feeling of loneliness and isolation I have ever experienced in my life.\\r\\nVenlafaxine not only trapped me inside my head - it also emptied my head of anything worth remembering, and left me barely able to learn new things. \\r\\nI&#039;d sit around tables with people and realise I couldn&#039;t remember the names of people I&#039;d know for years - or even family members. \\r\\nI&#039;d hear a song playing and say &quot;Hey - what&#039;s the name of this dance?&quot;\\r\\nAny sentence longer than a few words requires a minute or so to compose when written. Spoken out loud? Forget about it. When I try to speak, I sound like the Goon from Popeye.\\r\\nAfter six weeks of hell, my doctor and I agreed to taper off my 75mg daily dose. This process lasted a month, not following a particular schedule (which might have been a better idea), and was mostly side effect free until I came down to 18.25mg a day - one half of one 37.5mg tablet.\\r\\nAfter three days of that, it really hit the fan. I got up one day, pottered around a bit, and suddenly decided that I wanted to kill myself. Literally out of nowhere.\\r\\nFortunately I was of sound enough mind to call the Samaritans, who recommended I call the emergency services, who sent an ambulance to take me to hospital. For suicidal thoughts. \\r\\nTo be honest, I&#039;d rather have gone to Disneyland.\\r\\nOnce I was in A&amp;E, I got to wait for several hours, just stewing in a room with a sofa and not much else. Then I met the most useless doctor of all time. After I refused his suggestion that I not only go back on Venlafaxine, but *try a higher dose* than the one that got me into this mess in the first place, he said there wasn&#039;t anything else they could do - and handed me a little leaflet for a local mental health charity meetup that happens every so often.\\r\\nBy this point I&#039;d decided that suicide would not be the best option - and nor would going on even more Venlafaxine than before. I also binned the leaflet on my way out, determined to keep going and just deal with the withdrawal.\\r\\nSince that time, my intelligence level has plummeted to the point of being humiliating. But that&#039;s not even the worst of it.\\r\\nAs I mentioned before, I started taking Venlafaxine for migraines. Now that I&#039;m not taking it, they&#039;re coming back again - but they&#039;ve also changed.\\r\\nA few days ago, days before the party I should probably have stayed home for only I couldn&#039;t stand sitting at home any longer so I went and ended up alone in a darkened room and felt more depressed than I have in my entire life, I was at home when I collapsed. The right side of my body gave way, I hit the wall, and fell on the floor where I lay frozen for God knows how long. Then when I did get up, I realised I couldn&#039;t speak at all, the right side of my body was almost paralysed, and the right side of my head was numb on the outside, and in agony on the inside.\\r\\nAfter calling the emergency services again, I was taken through the standard questions I guess they ask everyone when they think the person in question is having a stroke. Like the suicidal thoughts, stroke symptoms were a new experience for me. Thanks, Venlafaxine.\\r\\nWhen the ambulance arrived, they were able to reassure me that I wasn&#039;t having a stroke, as one side of my face wasn&#039;t drooping. This was good news - but since they couldn&#039;t explain what was actually going on, I was taking to hospital for a brain scan and blood tests and a meeting with a doctor who told me I&#039;d had a right-sided hemiplegic migraine. I&#039;d never had one before, and didn&#039;t know they existed until then; my migraines have always felt like my head is both in a vice and exploding at the same time, and I get them across my whole head, not just one side.\\r\\nAt this point, I&#039;m determined to continue fighting the withdrawal symptoms. The only thing that&#039;s really helped me in doing this was the discovery of a cognitive distortion called &quot;emotional reasoning&quot;. This involves assuming that because you feel bad, things must actually be bad.\\r\\nObviously emotional reasoning (which is worth Googling as it&#039;s quite an in depth subject, or at least feels like it given that my brain&#039;s been hopefully temporarily damaged by Venlafaxine) is pretty common in depression. It&#039;s also been my brain&#039;s default way of operating possibly for as long as I can remember, but definitely since I started taking Venlafaxine. The emotional and physical and psychological rollercoaster Venlafaxine puts you through is utterly exhausting - and while it&#039;s throwing you all over the place and especially during withdrawal it&#039;s tough to keep in mind that a lot of the negative thoughts your mind throws up are going to be based on how you feel (i.e. the levels and mix of different chemicals in your brain), NOT on any Real Life Stuff. You&#039;ll most likely unintentionally filter out all the good stuff in your brain and only remember the darkest and worst things you possibly can, and attach all kinds of apparently logical arguments to make a case against yourself / a case that argues that you and your life are awful.\\r\\nLooking back on this experience, my thoughts were similar to one of those films you see advertised as &quot;...based on a true story&quot;. Works of fiction based very loosely on facts.\\r\\nRather than a film you&#039;d give two stars and never watch again, emotional reasoning&#039;s end product is a lie - not to mention the most toxic thoughts a human being can think. Depression can definitely make people tell these lies to themselves - but Venlafaxine made my brain malfunction so badly that putting together an apparently sensible argument for any depressive thoughts suddenly seemed like the most obvious thing in the world one day.\\r\\nIf I hadn&#039;t had those thoughts, I would&#039;ve just made lunch.\\r\\nSo that&#039;s about it for now - if I don&#039;t update this story in the future, assume I got better and decided to never revisit this page again, preferring to leave Venlafaxine and its horrific toxicity behind me. Good luck with your own journey :)\"',\n",
       "  '\"I don&rsquo;t find a lot of positive stories about antidepressants, or I find stories where people are taking the antidepressant the wrong way.\\r\\n\\r\\nI wanted to share my experience.  A positive one.\\r\\n\\r\\nI&rsquo;ve had generalized anxiety disorder, SEVERE OCD, and panic disorder for as long as I can remember.  My first memory of having an episode was when I was 4 years old at my kindergarten interview.  I feel as though I was born with the illnesses mentioned above, right from the womb.  When I was a child I was extremely anxious, had bad separation anxiety from my parents and had extreme OCD, I was just a kid and thought that the way I was feeling is how all kids felt, I didn&rsquo;t realize that I was different.  This went on, and got even worse in middle school.  I began developing trichtilomania in middle school.  In high school I went from being a 90% above student, to failing every class within a couple of years.  I couldn&rsquo;t leave the house.  My panic disorder and gad caused debilitating physical symptoms.  I would be shaking when I had to leave the house, I wouldn&rsquo;t drink alcohol because I was afraid of vomiting, I was suffering so much, for my whole entire life with severe phobias, fears, and anxiety.  I prayed and prayed and prayed to God every night for it to go away.  I was a 16 year old living in a prison of her own mind.  It never went away.  Every single day was the worst day of my life, I would wake up and the thoughts just started,  I never had a break.  My life was exhausting.\\r\\n\\r\\nI am of east indian background and my parents didn&rsquo;t understand mental illness well.  It is very taboo in my culture.  I went to tons of doctors and they told me it was just growing pains,  no doctor ever told me that maybe I should see a therapist.  I didn&rsquo;t have any support.  When I was 22 I attempted suicide.  Luckily the attempt didn&rsquo;t work and I was forced to go on medication.  I was livid, I was so against antidepressants, I was so so so scared, it felt unnatural. My general practitioner put me on Effexor, I took it for almost 8 weeks, it helped me to not want to kill myself, but It also made me gain tons of weight which made me depressed, and it make me hear voices.  One evening a voice told me to choke my mom, and I started freaking out and my parents drove me immediately to the hospital.  At the hospital I talked to a psych nurse who calmed me down, and got me an appointment with a psychiatrist the next day.  This appointment and this psychiatrist saved my life, and changed my entire life.\\r\\n\\r\\nI want to really mention that you should not be going to a General Practitioner for mental illness medication, you should ALWAYS&hellip;ALWAYS go to a psychiatrist no matter what.  If your GP is the only person you are seeing to help you manage your meds for ocd, anxiety, etc, that is the WRONG MOVE.  That is such a common mistake people are making, you NEED a psychiatrist in order to get the meds right, please do not just go to your regular doctor, you&rsquo;ll be cheating yourself.\\r\\n\\r\\nI went to the psychiatrist appointment the next day.  It was the first time I had ever seen a psychiatrist.   I got into her room and we talked about everything, my childhood, my phobias, my ocd.  She then brought my parents into the room to explain the whole situation to them and the fact that I have a chemical imbalance in my brain and that I have been suffering for way too long.  My parents were so supportive.  The doctor told me I was on the wrong medication, that I never should have been placed on Effexor which is an SNRI, and that I should be on an SSRI considering my main problem is OCD and GAD.  We talked a lot about it and she told me she would like to place me on Prozac.  She said for me, because my neural pathways have been the same for 20 plus years, that I would need a higher dosage of Prozac especially for anxiety and OCD.   I see on this forum, that so many people are on 20mg, or 40mg for anxiety disorders.   You should be on 60mg at least, do not be afraid to go higher.  People that say Prozac or an SSRI didn&rsquo;t really do anything for their anxiety or ocd is because they are only taking a 20mg dose,  That is not an OCD dose.  40-80mg for anxiety and OCD.   Please up your dose.   Use the medication, REALLY USE IT.  Do not be afraid!\\r\\n\\r\\nMy doctor started me on 40mg, eventually took me to 100mg, and then I went back to 80mg.  Yes the side effects are insane, I was nauseated, I couldn&rsquo;t sleep, I was shaking, I had anxiety, but she prescribed me Ativan and said to use it until the Prozac kicked in.  That the Ativan would keep me comfortable until that happened.  Don&rsquo;t try to be a hero, use your Ativan or your Xanax or whatever to stay as comfortable as possible.\\r\\n\\r\\nI could write so much more, but I&rsquo;ll conclude with this.  4 months after being on 80mg of Prozac everyday, I woke up one day and I was cured.   Yes cured.  I had no OCD, I had no anxiety, I no longer had fears or phobias.   I was cured.   You have no idea how that day felt.  It was like the first day of my whole entire life.  I woke up being the real me, who is free spirited and isn&rsquo;t afraid of anything!  I was finally free, I was no longer a prisoner.  I didn&rsquo;t even have to go to therapy.  I just woke up one day a brand new person, from taking a high dose of Prozac every single day.\\r\\n\\r\\nDO NOT go off of the antidepressants.   Your ocd, your anxiety, depression etc will come back.  I WOULD never dream or even think to come off of my antidepressants,  I have an illness, that will return if I go off the medication, because I have a brain disorder.  OCD is a brain disorder.  Do not stop taking medication for your brain disorder, do not try to fix your brain disorder with just a 20mg or 40mg dose.  Own your medication, be on it for life.\\r\\n\\r\\nIt&rsquo;s been 5 years since I have been cured.  If it wasn&rsquo;t for Prozac, I would be dead.\\r\\n\\r\\n1)\\tYou need a psychiatrist\\r\\n2)\\tDo not be afraid to take more than 40mg of Prozac to treat panic attacks etc,  I am on 80mg a day and my life is a ball.  It is so wonderful and so carefree.\\r\\n3)\\tDo not stop the meds.  Be on the meds for life.\"',\n",
       "  '\"My Complicated experience with the insertion of the copper IUD. It was &quot;one of the most difficult &amp; Complicated IUD insertions I&#039;ve had in a very long time&quot; quoting the words of my Gynecologist MD. Now I have not been sexually active for over a year and a half (by choice) &amp; I&#039;ve never had kids so that for one was a concern for my doctor since she said i might be very tight &amp; feel pain. Anywhom I am 23 and recently decided to date again &amp; wanted to have a convinient birth control that won&#039;t affect my weight or cause acne since acne has recently been a new battle for me, so my first step was hitting the Internet for options. After reading many reviews for multiple birth controls I decided on the copper para guard which is for 10-12 years. Now I went to my doctor and had a screening for STDs &amp; HIV which is protocol to any birth control procedure. Then pregnancy tests were taken a few days before the insertion and the day of the insertion, after everything came out negative I was ready for my IUD. I was schedule to go in on Tuesday September 1, 2015 so I went in with anticipation of pain and I was very nervous. Mostly because it was something new for me to have a speculum inside me since I just had my first Pap smear ,ever, two weeks prior to the IUD insertion. As my doctor placed the speculum I had some discomfort, she had trouble finding my cervix, after some time she had everything positioned right and began to try and dilate my cervix, right when she started I began to feel extreme cramping. My doctor could not get her tool that she used to dilate my cervix to stay in, I was too tight due to the fact that I&#039;ve never had kids so it wasn&#039;t easy, my cervix kept pushing the prob out. She attempted a few more times until I couldn&#039;t take the pain anymore because the cramping became so severe I began to cry. Now I know i sound ridiculous crying but I have a pretty high tolerance for pain &amp; I never understood how many woman couldn&#039;t take the cramping they had when on their period because I don&#039;t experience cramping on my periods, at least until now. I now have so much more sympathy for those who do have this pain every month. My doctor gave me other birth control options because she wasn&#039;t successful in Inserting the IUD but she knew I didn&#039;t want others so she offered to use an anesthetic on my cervix to help with the insertion (which is not normally a part of the procedure but since I had a special case she offered this option to me). I was not happy with the fact that I had to have a needle inserted in my cervix but this was the birth control I wanted and I was going to do whatever to get it. I was in too much pain that day so I had to come back the next morning. So here I go Wednesday morning into my doctors office, laying down ready to get a needle inserted into my cervix which terrified me because I already knew how painful it was but I didn&#039;t feel a thing when she put the anesthetic, I was told I would feel a slight sting and some burning sensation but I didn&#039;t feel anything. It took her about 15 min to position the IUD correctly, she had to dilate me 8cm to get a good view and make sure I had a successful insertion. I felt NOTHING &amp; then she was done. Right after she had me lay down for a few minutes then had me slowly sit up, I felt like I was going to faint, The MD said my eyes were not focusing on her and I was so pale. At that point my whole face and hands where numb. She stayed there with me until I regained full blood flow to my upper body. FYI my doctor said some woman actually faint after the procedure &amp; in some rare cases they even have seizure because the pain of dilating the cervix is so intense. I was lucky of not having any cramps because my cervix was numb. 8 hrs later the numbness began to fade &amp; the pain started, I got prescribed 600 Tylenol which helped a little. I spotted the next 3 days, I had to use pantie liners. Then my period came 1 week early just 4 days after I got my IUD placed, it was very heavy the first 3 days with medium cramping and my period lasted 5 1/2 days. My usual periods post the IUD was 4 days with only 1 heavy day. I have now had my IUD going on 3 weeks and I have little spotting every day so I use liners all the time. Now the part that I was most nervous about was the whole &quot;me checking if I can feel the IUD strings&quot; Its something I&#039;m a bit uncomfortable doing mostly because I&#039;ve never done it before so the first couple of times I tried to check for the strings I couldn&#039;t feel anything so I began to freak out and rushed to my doctors office after my unsuccessful attempts. She said to wait until my first period was over and then to try again. I tried again after my period and I still couldn&#039;t feel anything then I found a way to check that best fits me since I have small hands so I&#039;ll share my wisdom with you guys lol. I check in the shower every morning I lift one leg as if I&#039;m going to shave then I insert my pointer and I squat a little which helps and I&#039;m able to feel the tip of the strings. I have not had any cramping since my period and my discharge has reduced. I&#039;m very happy with my IUD &amp; I plan on using it safely and responsibly as I have heard many woman have got pregnant with the IUD. I still plan on using condoms because of STDs and I got the IUD as a backup just in case. I plan on keeping it for the full 10 year unless there are any complications. Sorry for the long story but I for one would have loved to hear the entire experience someone had so I decided to share mine. Hope it helps at least one person :)\"'],\n",
       " 'rating': [2.0, 10.0, 10.0],\n",
       " 'date': ['June 18, 2017', 'May 26, 2017', 'September 17, 2015'],\n",
       " 'usefulCount': [9, 148, 43],\n",
       " 'review_length': [1894, 1162, 1107]}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "foo = drug_dataset.sort('review_length', reverse=True)\n",
    "foo['train'][:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9fb8215a-123f-4d72-88c1-b0527c923053",
   "metadata": {},
   "outputs": [],
   "source": [
    "import html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "436b05a9-f45b-4f9e-b7db-1af7247da692",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 9.12 ms, sys: 165 Âµs, total: 9.29 ms\n",
      "Wall time: 8.13 ms\n"
     ]
    }
   ],
   "source": [
    "%time drug_dataset = drug_dataset.map(lambda x: {\"review\": html.unescape(x[\"review\"])})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bc018be-50a5-4a65-a3e0-249dc32e1bd9",
   "metadata": {},
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ac364d3-f181-42f7-b615-d746173c88ac",
   "metadata": {},
   "source": [
    "`map` method's superpowers?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2f05cf3e-40ce-409a-8215-5009f94cbd71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.2 ms, sys: 8.1 ms, total: 12.3 ms\n",
      "Wall time: 9.44 ms\n"
     ]
    }
   ],
   "source": [
    "%time _ = drug_dataset.map(lambda x: {\"review\": [html.unescape(o) for o in x[\"review\"]]}, batched=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab27282c-4c9a-4383-a5bb-72dd04645a6c",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fa0bb09c-8b9c-43e9-8b7a-961c83ce5fa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer_slow = AutoTokenizer.from_pretrained(\"bert-base-cased\", use_fast=False)\n",
    "tokenizer_fast = AutoTokenizer.from_pretrained(\"bert-base-cased\", use_fast=True)\n",
    "\n",
    "def tokenize_function_slow(examples):\n",
    "    return tokenizer_slow(examples[\"review\"], truncation=True)\n",
    "\n",
    "def tokenize_function_fast(examples):\n",
    "    return tokenizer_fast(examples[\"review\"], truncation=True)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "fc047b67-688e-4f9d-9932-7fbe4d1ade93",
   "metadata": {},
   "source": [
    "%time _ = drug_dataset.map(tokenize_function_slow, batched=True)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "612eb230-1199-4d8a-aeb5-1a70760b983b",
   "metadata": {},
   "source": [
    "%time _ = drug_dataset.map(tokenize_function_slow, batched=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9590de31-eeb0-4b86-8676-4bc2af2a569e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 12.2 ms, sys: 8.53 ms, total: 20.7 ms\n",
      "Wall time: 18.7 ms\n"
     ]
    }
   ],
   "source": [
    "%time _ = drug_dataset.map(tokenize_function_fast, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "75fe5547-1872-4556-8b86-c185adcd8ca3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19d95fea529047c495d6b54a8e7b0266",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/46108 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 24.6 s, sys: 106 ms, total: 24.7 s\n",
      "Wall time: 24.7 s\n"
     ]
    }
   ],
   "source": [
    "%time _ = drug_dataset.map(tokenize_function_fast, batched=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe41a387-faea-4a89-9ecd-726a60e2e861",
   "metadata": {},
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "843309c4-5182-48dd-a645-15e61d64bd48",
   "metadata": {},
   "outputs": [],
   "source": [
    "slow_tokenizer = AutoTokenizer.from_pretrained(\"bert-base-cased\", use_fast=False)\n",
    "\n",
    "def slow_tokenize_function(examples):\n",
    "    return slow_tokenizer(examples[\"review\"], truncation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3c1abc9a-f3ed-4e59-92e2-58206acbf749",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 668 ms, sys: 0 ns, total: 668 ms\n",
      "Wall time: 666 ms\n"
     ]
    }
   ],
   "source": [
    "%time _ = drug_dataset.map(slow_tokenize_function, batched=True, num_proc=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c104b88-aec9-4a96-9fc3-a74640308e7f",
   "metadata": {},
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fd49086e-2882-4f90-bffe-b6a724191dc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# was this line left out of the tutorial???\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-cased\", use_fast=True)\n",
    "\n",
    "def tokenize_and_split(examples):\n",
    "    return tokenizer(\n",
    "        examples[\"review\"],\n",
    "        truncation=True,\n",
    "        max_length=128,\n",
    "        return_overflowing_tokens=True,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f6048ff7-95c6-43cb-9567-f614f97d862f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[128, 49]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = tokenize_and_split(drug_dataset[\"train\"][0])\n",
    "[len(inp) for inp in result[\"input_ids\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f2c15332-e05b-4e60-98d2-29961b64353a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3ac10a491ce4d34a6eefb55748fe22c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/138514 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "ArrowInvalid",
     "evalue": "Column 8 named input_ids expected length 1000 but got length 1463",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mArrowInvalid\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[32], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m tokenized_dataset \u001b[38;5;241m=\u001b[39m \u001b[43mdrug_dataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtokenize_and_split\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatched\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/learn-hf/lib/python3.9/site-packages/datasets/dataset_dict.py:886\u001b[0m, in \u001b[0;36mDatasetDict.map\u001b[0;34m(self, function, with_indices, with_rank, input_columns, batched, batch_size, drop_last_batch, remove_columns, keep_in_memory, load_from_cache_file, cache_file_names, writer_batch_size, features, disable_nullable, fn_kwargs, num_proc, desc)\u001b[0m\n\u001b[1;32m    883\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cache_file_names \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    884\u001b[0m     cache_file_names \u001b[38;5;241m=\u001b[39m {k: \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m}\n\u001b[1;32m    885\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m DatasetDict(\n\u001b[0;32m--> 886\u001b[0m     {\n\u001b[1;32m    887\u001b[0m         k: dataset\u001b[38;5;241m.\u001b[39mmap(\n\u001b[1;32m    888\u001b[0m             function\u001b[38;5;241m=\u001b[39mfunction,\n\u001b[1;32m    889\u001b[0m             with_indices\u001b[38;5;241m=\u001b[39mwith_indices,\n\u001b[1;32m    890\u001b[0m             with_rank\u001b[38;5;241m=\u001b[39mwith_rank,\n\u001b[1;32m    891\u001b[0m             input_columns\u001b[38;5;241m=\u001b[39minput_columns,\n\u001b[1;32m    892\u001b[0m             batched\u001b[38;5;241m=\u001b[39mbatched,\n\u001b[1;32m    893\u001b[0m             batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[1;32m    894\u001b[0m             drop_last_batch\u001b[38;5;241m=\u001b[39mdrop_last_batch,\n\u001b[1;32m    895\u001b[0m             remove_columns\u001b[38;5;241m=\u001b[39mremove_columns,\n\u001b[1;32m    896\u001b[0m             keep_in_memory\u001b[38;5;241m=\u001b[39mkeep_in_memory,\n\u001b[1;32m    897\u001b[0m             load_from_cache_file\u001b[38;5;241m=\u001b[39mload_from_cache_file,\n\u001b[1;32m    898\u001b[0m             cache_file_name\u001b[38;5;241m=\u001b[39mcache_file_names[k],\n\u001b[1;32m    899\u001b[0m             writer_batch_size\u001b[38;5;241m=\u001b[39mwriter_batch_size,\n\u001b[1;32m    900\u001b[0m             features\u001b[38;5;241m=\u001b[39mfeatures,\n\u001b[1;32m    901\u001b[0m             disable_nullable\u001b[38;5;241m=\u001b[39mdisable_nullable,\n\u001b[1;32m    902\u001b[0m             fn_kwargs\u001b[38;5;241m=\u001b[39mfn_kwargs,\n\u001b[1;32m    903\u001b[0m             num_proc\u001b[38;5;241m=\u001b[39mnum_proc,\n\u001b[1;32m    904\u001b[0m             desc\u001b[38;5;241m=\u001b[39mdesc,\n\u001b[1;32m    905\u001b[0m         )\n\u001b[1;32m    906\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m k, dataset \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems()\n\u001b[1;32m    907\u001b[0m     }\n\u001b[1;32m    908\u001b[0m )\n",
      "File \u001b[0;32m/opt/conda/envs/learn-hf/lib/python3.9/site-packages/datasets/dataset_dict.py:887\u001b[0m, in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    883\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cache_file_names \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    884\u001b[0m     cache_file_names \u001b[38;5;241m=\u001b[39m {k: \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m}\n\u001b[1;32m    885\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m DatasetDict(\n\u001b[1;32m    886\u001b[0m     {\n\u001b[0;32m--> 887\u001b[0m         k: \u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    888\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfunction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    889\u001b[0m \u001b[43m            \u001b[49m\u001b[43mwith_indices\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwith_indices\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    890\u001b[0m \u001b[43m            \u001b[49m\u001b[43mwith_rank\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwith_rank\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    891\u001b[0m \u001b[43m            \u001b[49m\u001b[43minput_columns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_columns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    892\u001b[0m \u001b[43m            \u001b[49m\u001b[43mbatched\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatched\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    893\u001b[0m \u001b[43m            \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    894\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdrop_last_batch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdrop_last_batch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    895\u001b[0m \u001b[43m            \u001b[49m\u001b[43mremove_columns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mremove_columns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    896\u001b[0m \u001b[43m            \u001b[49m\u001b[43mkeep_in_memory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeep_in_memory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    897\u001b[0m \u001b[43m            \u001b[49m\u001b[43mload_from_cache_file\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mload_from_cache_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    898\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcache_file_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_file_names\u001b[49m\u001b[43m[\u001b[49m\u001b[43mk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    899\u001b[0m \u001b[43m            \u001b[49m\u001b[43mwriter_batch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwriter_batch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    900\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfeatures\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfeatures\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    901\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdisable_nullable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdisable_nullable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    902\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfn_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfn_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    903\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnum_proc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_proc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    904\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdesc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdesc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    905\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    906\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m k, dataset \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems()\n\u001b[1;32m    907\u001b[0m     }\n\u001b[1;32m    908\u001b[0m )\n",
      "File \u001b[0;32m/opt/conda/envs/learn-hf/lib/python3.9/site-packages/datasets/arrow_dataset.py:560\u001b[0m, in \u001b[0;36mtransmit_format.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    553\u001b[0m self_format \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    554\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_type,\n\u001b[1;32m    555\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mformat_kwargs\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_kwargs,\n\u001b[1;32m    556\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_columns,\n\u001b[1;32m    557\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput_all_columns\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output_all_columns,\n\u001b[1;32m    558\u001b[0m }\n\u001b[1;32m    559\u001b[0m \u001b[38;5;66;03m# apply actual function\u001b[39;00m\n\u001b[0;32m--> 560\u001b[0m out: Union[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDatasetDict\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    561\u001b[0m datasets: List[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(out\u001b[38;5;241m.\u001b[39mvalues()) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(out, \u001b[38;5;28mdict\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m [out]\n\u001b[1;32m    562\u001b[0m \u001b[38;5;66;03m# re-apply format to the output\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/envs/learn-hf/lib/python3.9/site-packages/datasets/arrow_dataset.py:3073\u001b[0m, in \u001b[0;36mDataset.map\u001b[0;34m(self, function, with_indices, with_rank, input_columns, batched, batch_size, drop_last_batch, remove_columns, keep_in_memory, load_from_cache_file, cache_file_name, writer_batch_size, features, disable_nullable, fn_kwargs, num_proc, suffix_template, new_fingerprint, desc)\u001b[0m\n\u001b[1;32m   3067\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m transformed_dataset \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   3068\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m hf_tqdm(\n\u001b[1;32m   3069\u001b[0m         unit\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m examples\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   3070\u001b[0m         total\u001b[38;5;241m=\u001b[39mpbar_total,\n\u001b[1;32m   3071\u001b[0m         desc\u001b[38;5;241m=\u001b[39mdesc \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMap\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   3072\u001b[0m     ) \u001b[38;5;28;01mas\u001b[39;00m pbar:\n\u001b[0;32m-> 3073\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m rank, done, content \u001b[38;5;129;01min\u001b[39;00m Dataset\u001b[38;5;241m.\u001b[39m_map_single(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mdataset_kwargs):\n\u001b[1;32m   3074\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m done:\n\u001b[1;32m   3075\u001b[0m                 shards_done \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m/opt/conda/envs/learn-hf/lib/python3.9/site-packages/datasets/arrow_dataset.py:3499\u001b[0m, in \u001b[0;36mDataset._map_single\u001b[0;34m(shard, function, with_indices, with_rank, input_columns, batched, batch_size, drop_last_batch, remove_columns, keep_in_memory, cache_file_name, writer_batch_size, features, disable_nullable, fn_kwargs, new_fingerprint, rank, offset)\u001b[0m\n\u001b[1;32m   3497\u001b[0m         writer\u001b[38;5;241m.\u001b[39mwrite_table(batch\u001b[38;5;241m.\u001b[39mto_arrow())\n\u001b[1;32m   3498\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 3499\u001b[0m         \u001b[43mwriter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3500\u001b[0m num_examples_progress_update \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m num_examples_in_batch\n\u001b[1;32m   3501\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m>\u001b[39m _time \u001b[38;5;241m+\u001b[39m config\u001b[38;5;241m.\u001b[39mPBAR_REFRESH_TIME_INTERVAL:\n",
      "File \u001b[0;32m/opt/conda/envs/learn-hf/lib/python3.9/site-packages/datasets/arrow_writer.py:608\u001b[0m, in \u001b[0;36mArrowWriter.write_batch\u001b[0;34m(self, batch_examples, writer_batch_size)\u001b[0m\n\u001b[1;32m    606\u001b[0m         inferred_features[col] \u001b[38;5;241m=\u001b[39m typed_sequence\u001b[38;5;241m.\u001b[39mget_inferred_type()\n\u001b[1;32m    607\u001b[0m schema \u001b[38;5;241m=\u001b[39m inferred_features\u001b[38;5;241m.\u001b[39marrow_schema \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpa_writer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mschema\n\u001b[0;32m--> 608\u001b[0m pa_table \u001b[38;5;241m=\u001b[39m \u001b[43mpa\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_arrays\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrays\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mschema\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mschema\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    609\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwrite_table(pa_table, writer_batch_size)\n",
      "File \u001b[0;32m/opt/conda/envs/learn-hf/lib/python3.9/site-packages/pyarrow/table.pxi:4868\u001b[0m, in \u001b[0;36mpyarrow.lib.Table.from_arrays\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/opt/conda/envs/learn-hf/lib/python3.9/site-packages/pyarrow/table.pxi:4214\u001b[0m, in \u001b[0;36mpyarrow.lib.Table.validate\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/opt/conda/envs/learn-hf/lib/python3.9/site-packages/pyarrow/error.pxi:92\u001b[0m, in \u001b[0;36mpyarrow.lib.check_status\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mArrowInvalid\u001b[0m: Column 8 named input_ids expected length 1000 but got length 1463"
     ]
    }
   ],
   "source": [
    "tokenized_dataset = drug_dataset.map(tokenize_and_split, batched=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51fac824-248d-4fd0-8031-2d6e23b69394",
   "metadata": {},
   "source": [
    "> The problem is that weâ€™re trying to mix two different datasets of different sizes: the drug_dataset columns will have a certain number of examples (the 1,000 in our error), but the tokenized_dataset we are building will have more (the 1,463 in the error message; it is more than 1,000 because we are tokenizing long reviews into more than one example by using return_overflowing_tokens=True). That doesnâ€™t work for a Dataset, so we need to either remove the columns from the old dataset or make them the same size as they are in the new dataset....\n",
    "\n",
    "##### Clarification\n",
    "* We are trying to build a new dataset of tokenized values that we will use for training.\n",
    "* Since we are splitting each original row in `drug_dataset` so that we have an initial 128-token value and possibly and additional set of tokens from those rows where there are more than 128 tokens (overflow), we are essentially not going to be able to do a one-to-one mapping from the original `drug_dataset` to our new tokenized one.\n",
    "* So we need to use the [`remove_columns` argument to to `datasets.map`](https://huggingface.co/docs/datasets/v3.2.0/en/package_reference/main_classes#datasets.Dataset.map.remove_columns), which _...removes a selection of columns while doing the mapping. Columns will be removed before updating the examples with the output of function, i.e. if function is adding columns with names in remove_columns, these columns will be kept_\n",
    "* You would do well to remember that in this instance for training, the **tokenized** dataset is expected to have the following fields: `input_ids`, `token_type_ids`, and `attention_mask`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2265e2c4-e783-47f3-a5b2-0bb56ffe4a9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_dataset = drug_dataset.map(\n",
    "    tokenize_and_split, batched=True, remove_columns=drug_dataset[\"train\"].column_names\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8c1429e-a073-4ce4-a586-866081d73a9b",
   "metadata": {},
   "source": [
    "...\n",
    "\n",
    "Now compare the resulting `tokenized_dataset` vis a vis the original `drug_dataset`..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "70266004-5221-464d-96d2-b5bd63ea760d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(206772, 138514)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenized_dataset[\"train\"]), len(drug_dataset[\"train\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6f0d12cf-8ab7-4c04-8823-c86baa10b6fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['input_ids', 'token_type_ids', 'attention_mask', 'overflow_to_sample_mapping'],\n",
       "        num_rows: 206772\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['input_ids', 'token_type_ids', 'attention_mask', 'overflow_to_sample_mapping'],\n",
       "        num_rows: 68876\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "fc11f448-e2d6-42d7-a3d1-5bc071db6bbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': [101, 107, 1130, 19972, 11083, 1225, 1136, 1250, 1111, 1139, 1488, 132, 1119, 1108, 18302, 1228, 1103, 2928, 1229, 1119, 1108, 1781, 1122, 117, 1105, 1515, 1558, 2492, 1107, 1705, 106, 1135, 3093, 1106, 1250, 1103, 3714, 1113, 1140, 106, 107, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'overflow_to_sample_mapping': 43}\n"
     ]
    }
   ],
   "source": [
    "print(tokenized_dataset[\"train\"][66])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a4845b0d-f61b-4b4b-a98b-916275462d8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['patient_id', 'drugName', 'condition', 'review', 'rating', 'date', 'usefulCount', 'review_length'],\n",
       "        num_rows: 138514\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['patient_id', 'drugName', 'condition', 'review', 'rating', 'date', 'usefulCount', 'review_length'],\n",
       "        num_rows: 46108\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "drug_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7580fa91-e198-4efb-af97-5358acbfce45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'patient_id': 95260, 'drugName': 'Guanfacine', 'condition': 'adhd', 'review': '\"My son is halfway through his fourth week of Intuniv. We became concerned when he began this last week, when he started taking the highest dose he will be on. For two days, he could hardly get out of bed, was very cranky, and slept for nearly 8 hours on a drive home from school vacation (very unusual for him.) I called his doctor on Monday morning and she said to stick it out a few days. See how he did at school, and with getting up in the morning. The last two days have been problem free. He is MUCH more agreeable than ever. He is less emotional (a good thing), less cranky. He is remembering all the things he should. Overall his behavior is better. \\r\\nWe have tried many different medications and so far this is the most effective.\"', 'rating': 8.0, 'date': 'April 27, 2010', 'usefulCount': 192, 'review_length': 141}\n"
     ]
    }
   ],
   "source": [
    "print(drug_dataset[\"train\"][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2424e682-4a2f-4a6f-95b3-6d7107c1b8e4",
   "metadata": {},
   "source": [
    "<hr width=40%/>\n",
    "\n",
    "##### Uh, wtf? Or, I think we need a bit more clarification...\n",
    "\n",
    "OK, that HF tutorial is not at all clear as to what happens with `return_overflowing_tokens`. \n",
    "\n",
    "Let's take a quick detour and dig in just a bit more..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "24a76291-5dd8-4f2c-86a9-9dfcbd484ade",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Original example string: this is an example and context is important to retrieve meaningful contextualized token embeddings from the self attention mechanism of the transformer\n",
      "\n",
      "Tokenized, this string has 32 tokens:\n",
      "['<s>', 'this', 'is', 'an', 'example', 'and', 'context', 'is', 'important', 'to', 're', 'tri', 'eve', 'meaning', 'ful', 'context', 'ual', 'ized', 'to', 'ken', '', 'embe', 'dding', 's', 'from', 'the', 'self', 'attention', 'mechanism', 'of', 'the', 'transform', 'er', '</s>']\n"
     ]
    }
   ],
   "source": [
    "from transformers import XLMRobertaTokenizerFast\n",
    "\n",
    "model_id = \"xlm-roberta-large-finetuned-conll03-english\"\n",
    "t = XLMRobertaTokenizerFast.from_pretrained(model_id)\n",
    "\n",
    "sample = \"this is an example and context is important to retrieve meaningful contextualized token embeddings from the self attention mechanism of the transformer\"\n",
    "encoded_default = t(sample, truncation=True).input_ids\n",
    "\n",
    "print()\n",
    "print(f\"Original example string: {sample}\")\n",
    "print()\n",
    "print(f\"Tokenized, this string has {len(t.tokenize(sample))} tokens:\\n{t.batch_decode(encoded_default)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "855968eb-0beb-47c5-aa87-9c22edb716b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting max_length in tokenization to: 10\n",
      "Now the tokens look like this:\n",
      "['<s>', 'this', 'is', 'an', 'example', 'and', 'context', 'is', 'important', '</s>']\n"
     ]
    }
   ],
   "source": [
    "# now let's limit tokenization to 10 tokens...\n",
    "encoded_max_length = t(sample, max_length=10, truncation=True).input_ids\n",
    "\n",
    "print(f\"Setting max_length in tokenization to: {len(encoded_max_length)}\")\n",
    "print(f\"Now the tokens look like this:\\n{t.batch_decode(encoded_max_length)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f0ad05c3-3185-4650-a116-a0a45deda635",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10, 10, 10, 10]\n",
      "<s> this is an example and context is important</s>\n",
      "<s> to retrieve meaningful contextual</s>\n",
      "<s>ized token embeddings from</s>\n",
      "<s> the self attention mechanism of the transformer</s>\n"
     ]
    }
   ],
   "source": [
    "# and NOW we ask the tokenizer to return_overflowing_tokens\n",
    "encoded_overflow = t(sample, max_length=10, truncation=True, return_overflowing_tokens=True).input_ids\n",
    "\n",
    "print([len(x) for x in encoded_overflow])\n",
    "print(*t.batch_decode(encoded_overflow), sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c3d90c08-02ac-4552-a0eb-91e2b52df8da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10, 10, 10, 10, 10, 9]\n",
      "<s> this is an example and context is important</s>\n",
      "<s> context is important to retrieve meaning</s>\n",
      "<s>trieve meaningful contextualized to</s>\n",
      "<s>ualized token embeddings</s>\n",
      "<s>embeddings from the self attention mechanism</s>\n",
      "<s> self attention mechanism of the transformer</s>\n"
     ]
    }
   ],
   "source": [
    "# but it may be the case that this sequential listing of the overflow \n",
    "# results is less-than-ideal input...\n",
    "# so NOW we ask for striding of the overflow\n",
    "# with the hope that the resulting strided sequences make more sense\n",
    "encoded_overflow_stride = t(sample, max_length=10, truncation=True, stride=3, return_overflowing_tokens=True).input_ids\n",
    "\n",
    "print([len(x) for x in encoded_overflow_stride])\n",
    "print(*t.batch_decode(encoded_overflow_stride), sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66981b5a-a1d1-4517-bc50-4340ebca9db7",
   "metadata": {},
   "source": [
    "<hr width=40%/>\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "465f9a11-7208-44b7-88b7-6a49b0681b9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_and_split(examples):\n",
    "    result = tokenizer(\n",
    "        examples[\"review\"],\n",
    "        truncation=True,\n",
    "        max_length=128,\n",
    "        return_overflowing_tokens=True,\n",
    "    )\n",
    "\n",
    "    # Extract mapping between new and old indices\n",
    "    sample_map = result.pop(\"overflow_to_sample_mapping\")\n",
    "    for key, values in examples.items():\n",
    "        result[key] = [values[i] for i in sample_map]\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d9e85ee3-1a83-45b4-82a2-db17b64b8480",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['patient_id', 'drugName', 'condition', 'review', 'rating', 'date', 'usefulCount', 'review_length', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 206772\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['patient_id', 'drugName', 'condition', 'review', 'rating', 'date', 'usefulCount', 'review_length', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 68876\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "drug_dataset = drug_dataset.map(tokenize_and_split, batched=True)\n",
    "drug_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "311c9c59-ad95-4d32-bd14-659e54a825bd",
   "metadata": {},
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "61daf6f9-b225-4549-ba41-11caeef04649",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>patient_id</th>\n",
       "      <th>drugName</th>\n",
       "      <th>condition</th>\n",
       "      <th>review</th>\n",
       "      <th>rating</th>\n",
       "      <th>date</th>\n",
       "      <th>usefulCount</th>\n",
       "      <th>review_length</th>\n",
       "      <th>input_ids</th>\n",
       "      <th>token_type_ids</th>\n",
       "      <th>attention_mask</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>95260</td>\n",
       "      <td>Guanfacine</td>\n",
       "      <td>adhd</td>\n",
       "      <td>\"My son is halfway through his fourth week of ...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>April 27, 2010</td>\n",
       "      <td>192</td>\n",
       "      <td>141</td>\n",
       "      <td>[101, 107, 1422, 1488, 1110, 9079, 1194, 1117,...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>95260</td>\n",
       "      <td>Guanfacine</td>\n",
       "      <td>adhd</td>\n",
       "      <td>\"My son is halfway through his fourth week of ...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>April 27, 2010</td>\n",
       "      <td>192</td>\n",
       "      <td>141</td>\n",
       "      <td>[101, 119, 1124, 1110, 1750, 6438, 113, 170, 1...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>92703</td>\n",
       "      <td>Lybrel</td>\n",
       "      <td>birth control</td>\n",
       "      <td>\"I used to take another oral contraceptive, wh...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>December 14, 2009</td>\n",
       "      <td>17</td>\n",
       "      <td>134</td>\n",
       "      <td>[101, 107, 146, 1215, 1106, 1321, 1330, 9619, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   patient_id    drugName      condition  \\\n",
       "0       95260  Guanfacine           adhd   \n",
       "1       95260  Guanfacine           adhd   \n",
       "2       92703      Lybrel  birth control   \n",
       "\n",
       "                                              review  rating  \\\n",
       "0  \"My son is halfway through his fourth week of ...     8.0   \n",
       "1  \"My son is halfway through his fourth week of ...     8.0   \n",
       "2  \"I used to take another oral contraceptive, wh...     5.0   \n",
       "\n",
       "                date  usefulCount  review_length  \\\n",
       "0     April 27, 2010          192            141   \n",
       "1     April 27, 2010          192            141   \n",
       "2  December 14, 2009           17            134   \n",
       "\n",
       "                                           input_ids  \\\n",
       "0  [101, 107, 1422, 1488, 1110, 9079, 1194, 1117,...   \n",
       "1  [101, 119, 1124, 1110, 1750, 6438, 113, 170, 1...   \n",
       "2  [101, 107, 146, 1215, 1106, 1321, 1330, 9619, ...   \n",
       "\n",
       "                                      token_type_ids  \\\n",
       "0  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "1  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "2  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "\n",
       "                                      attention_mask  \n",
       "0  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "1  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "2  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "drug_dataset.set_format(\"pandas\")\n",
    "drug_dataset[\"train\"][:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "498eb884-1a3c-4de7-a33c-5fd9bd991449",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = drug_dataset[\"train\"][:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "7681dbd2-3681-48f8-b1c0-97d83241faa8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>condition</th>\n",
       "      <th>frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>birth control</td>\n",
       "      <td>43445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>depression</td>\n",
       "      <td>12322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>acne</td>\n",
       "      <td>8285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>anxiety</td>\n",
       "      <td>7523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>pain</td>\n",
       "      <td>6513</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       condition  frequency\n",
       "0  birth control      43445\n",
       "1     depression      12322\n",
       "2           acne       8285\n",
       "3        anxiety       7523\n",
       "4           pain       6513"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frequencies = (\n",
    "    train_df[\"condition\"]\n",
    "    .value_counts()\n",
    "    .to_frame()\n",
    "    .reset_index()\n",
    "    .rename(columns={\"count\": \"frequency\"})\n",
    ")\n",
    "frequencies.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "769bebb0-ce78-4fc0-b1e1-334f11fe7f64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['condition', 'frequency'],\n",
       "    num_rows: 819\n",
       "})"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "freq_dataset = Dataset.from_pandas(frequencies)\n",
    "freq_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "cdd1e245-2dff-4794-9a69-2504353fd3b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                  drugName     rating\n",
      "0                A + D Cracked Skin Relief  10.000000\n",
      "1                               A / B Otic  10.000000\n",
      "2     Abacavir / dolutegravir / lamivudine   7.901639\n",
      "3       Abacavir / lamivudine / zidovudine   9.000000\n",
      "4                                Abatacept   7.500000\n",
      "...                                    ...        ...\n",
      "3047                                 Zyvox   9.210526\n",
      "3048                               ZzzQuil   4.000000\n",
      "3049                 depo-subQ provera 104   1.000000\n",
      "3050                                  ella   7.125000\n",
      "3051                                femhrt   5.500000\n",
      "\n",
      "[3052 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "drug_avg_rating = (\n",
    "    train_df.groupby(['drugName'])['rating']\n",
    "            .mean()\n",
    "            .to_frame()\n",
    "            .reset_index()\n",
    ")\n",
    "print(drug_avg_rating)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "8dc89a35-3be3-4572-96b5-8be18064e53e",
   "metadata": {},
   "outputs": [],
   "source": [
    "drug_dataset.reset_format()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cadb58b6-328e-40cb-869a-3f04652348d6",
   "metadata": {},
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "0172913a-9eb9-4a86-8894-2dcefcf65329",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['patient_id', 'drugName', 'condition', 'review', 'rating', 'date', 'usefulCount', 'review_length', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 206772\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['patient_id', 'drugName', 'condition', 'review', 'rating', 'date', 'usefulCount', 'review_length', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 68876\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "drug_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "e24819e1-3909-41d5-bfc9-ae83c51a5ddc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['patient_id', 'drugName', 'condition', 'review', 'rating', 'date', 'usefulCount', 'review_length', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 165417\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['patient_id', 'drugName', 'condition', 'review', 'rating', 'date', 'usefulCount', 'review_length', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 41355\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['patient_id', 'drugName', 'condition', 'review', 'rating', 'date', 'usefulCount', 'review_length', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 68876\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "drug_dataset_clean = drug_dataset[\"train\"].train_test_split(train_size=0.8, seed=42)\n",
    "\n",
    "# Rename the default \"test\" split to \"validation\"\n",
    "drug_dataset_clean[\"validation\"] = drug_dataset_clean.pop(\"test\")\n",
    "\n",
    "# Add the \"test\" set to our `DatasetDict`\n",
    "drug_dataset_clean[\"test\"] = drug_dataset[\"test\"]\n",
    "drug_dataset_clean"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a01d4690-8d03-4efa-aa73-943f8f1c7e00",
   "metadata": {},
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "1ef1366c-771b-40cd-9bb5-b6c2b32c86c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fdfcade026964251b0181e743a097b5c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/165417 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5a5eb42f4b145dcba85176d51acf3c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/41355 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3543c80f3e6c482a9626f1ed6879e391",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/68876 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "drug_dataset_clean.save_to_disk(\"drug-reviews\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "f8bae3fe-2584-454b-a9d8-0f70b4c7e69c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 24\n",
      "drwxr-xr-x 5 se_olliphant se_olliphant 4096 Feb  5 12:39 .\n",
      "drwxr-xr-x 5 se_olliphant se_olliphant 4096 Feb  5 12:42 ..\n",
      "-rw-r--r-- 1 se_olliphant se_olliphant   43 Feb  5 12:43 dataset_dict.json\n",
      "drwxr-xr-x 2 se_olliphant se_olliphant 4096 Feb  5 12:39 test\n",
      "drwxr-xr-x 2 se_olliphant se_olliphant 4096 Feb  5 12:39 train\n",
      "drwxr-xr-x 2 se_olliphant se_olliphant 4096 Feb  5 12:39 validation\n"
     ]
    }
   ],
   "source": [
    "!ls -la drug-reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "2d258ad1-77e3-4283-b748-eaaef3393618",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 191660\n",
      "drwxr-xr-x 2 se_olliphant se_olliphant      4096 Feb  5 12:39 .\n",
      "drwxr-xr-x 5 se_olliphant se_olliphant      4096 Feb  5 12:39 ..\n",
      "-rw-r--r-- 1 se_olliphant se_olliphant 196240960 Feb  5 12:44 data-00000-of-00001.arrow\n",
      "-rw-r--r-- 1 se_olliphant se_olliphant      1916 Feb  5 12:44 dataset_info.json\n",
      "-rw-r--r-- 1 se_olliphant se_olliphant       250 Feb  5 12:44 state.json\n"
     ]
    }
   ],
   "source": [
    "!ls -la drug-reviews/train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "ba9a7641-5d4a-475f-9b53-491c0345f417",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['patient_id', 'drugName', 'condition', 'review', 'rating', 'date', 'usefulCount', 'review_length', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 165417\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['patient_id', 'drugName', 'condition', 'review', 'rating', 'date', 'usefulCount', 'review_length', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 41355\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['patient_id', 'drugName', 'condition', 'review', 'rating', 'date', 'usefulCount', 'review_length', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 68876\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_from_disk\n",
    "\n",
    "drug_dataset_reloaded = load_from_disk(\"drug-reviews\")\n",
    "drug_dataset_reloaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "332d697e-c9f2-47e2-b651-2a2c4154bfe1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2f39ce2be9f400db7067416bc246b50",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating json from Arrow format:   0%|          | 0/166 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7063b87c142842bca08821ba7134d737",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating json from Arrow format:   0%|          | 0/42 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc27fedd62af4088bd0281a743fe7fbd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating json from Arrow format:   0%|          | 0/69 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for split, dataset in drug_dataset_clean.items():\n",
    "    dataset.to_json(f\"drug-reviews-{split}.jsonl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "38985292-7550-4a7f-b903-f0dafec9dacf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 627300\n",
      "drwxr-xr-x 5 se_olliphant se_olliphant      4096 Feb  5 12:42 .\n",
      "drwxr-xr-x 3 se_olliphant se_olliphant      4096 Jan 31 06:42 ..\n",
      "drwxr-xr-x 2 se_olliphant se_olliphant      4096 Feb  4 07:27 .ipynb_checkpoints\n",
      "-rw-r--r-- 1 se_olliphant se_olliphant     14239 Jan 31 07:05 Ch2_p38.ipynb\n",
      "-rw-r--r-- 1 se_olliphant se_olliphant     22696 Feb  1 04:21 HF_NLP_Ch2.ipynb\n",
      "-rw-r--r-- 1 se_olliphant se_olliphant     49292 Feb  4 03:25 HF_NLP_Ch3.ipynb\n",
      "-rw-r--r-- 1 se_olliphant se_olliphant      5472 Feb  4 03:26 HF_NLP_Ch4.ipynb\n",
      "-rw-r--r-- 1 se_olliphant se_olliphant     29410 Feb  5 12:42 HF_NLP_Ch5.ipynb\n",
      "-rw-r--r-- 1 se_olliphant se_olliphant   8385528 Feb  4 06:25 SQuAD_it-test.json\n",
      "-rw-r--r-- 1 se_olliphant se_olliphant   1051245 Feb  4 06:25 SQuAD_it-test.json.gz\n",
      "-rw-r--r-- 1 se_olliphant se_olliphant  43605829 Feb  4 06:25 SQuAD_it-train.json\n",
      "-rw-r--r-- 1 se_olliphant se_olliphant   7725286 Feb  4 06:25 SQuAD_it-train.json.gz\n",
      "-rw-r--r-- 1 se_olliphant se_olliphant      2417 Feb  2 03:48 Untitled.ipynb\n",
      "drwxr-xr-x 5 se_olliphant se_olliphant      4096 Feb  5 12:39 drug-reviews\n",
      "-rw-r--r-- 1 se_olliphant se_olliphant 106288152 Feb  5 12:44 drug-reviews-test.jsonl\n",
      "-rw-r--r-- 1 se_olliphant se_olliphant 255839630 Feb  5 12:44 drug-reviews-train.jsonl\n",
      "-rw-r--r-- 1 se_olliphant se_olliphant  63913350 Feb  5 12:44 drug-reviews-validation.jsonl\n",
      "-rw-r--r-- 1 se_olliphant se_olliphant  28071166 Oct  2  2018 drugsComTest_raw.tsv\n",
      "-rw-r--r-- 1 se_olliphant se_olliphant  84289175 Oct  2  2018 drugsComTrain_raw.tsv\n",
      "-rw-r--r-- 1 se_olliphant se_olliphant  42989872 Feb  4 07:30 drugsCom_raw.zip\n",
      "-rw-r--r-- 1 se_olliphant se_olliphant     14948 Feb  1 01:40 environment.yml\n",
      "drwxr-xr-x 5 se_olliphant se_olliphant      4096 Feb  2 03:58 test-trainer\n"
     ]
    }
   ],
   "source": [
    "!ls -la "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "834a5598-b632-44c9-8a39-70bcd69b4bf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"patient_id\":37933,\"drugName\":\"Adipex-P\",\"condition\":\"weight loss\",\"review\":\"\\\"Been on Adipex-p for 28 days and have lost 20 pounds. Doctor put me on it because I am menopausal and have a hard time losing weight. First week had a hard time sleeping but now no problems, I check my blood pressure daily and no issues there. Definitely get dry mouth with it that has been my only issue, I usually chew gum and keep a drink handy. Glad I was given this drug, doubt I would have lost what I did without it.\\\"\",\"rating\":9.0,\"date\":\"September 5, 2017\",\"usefulCount\":35,\"review_length\":85,\"input_ids\":[101,107,18511,1113,24930,9717,11708,118,185,1111,1743,1552,1105,1138,1575,1406,6549,119,4157,1508,1143,1113,1122,1272,146,1821,1441,4184,25134,1348,1105,1138,170,1662,1159,3196,2841,119,1752,1989,1125,170,1662,1159,5575,1133,1208,1185,2645,117,146,4031,1139,1892,2997,3828,1105,1185,2492,1175,119,3177,16598,3150,1193,1243,3712,1779,1114,1122,1115,1144,1151,1139,1178,2486,117,146,1932,22572,5773,19956,1105,1712,170,3668,25997,119,27652,146,1108,1549,1142,3850,117,4095,146,1156,1138,1575,1184,146,1225,1443,1122,119,107,102],\"token_type_ids\":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],\"attention_mask\":[1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1]}\n"
     ]
    }
   ],
   "source": [
    "!head -n 1 drug-reviews-train.jsonl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "d559f15f-0974-4660-b82c-5c89e803cc5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1097972987c7424d90345d21537b6c4e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5b4b21c255d4c71b20b75bfa75ea6fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67e8748ec0df4757a1e35db34acf4269",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_files = {\n",
    "    \"train\": \"drug-reviews-train.jsonl\",\n",
    "    \"validation\": \"drug-reviews-validation.jsonl\",\n",
    "    \"test\": \"drug-reviews-test.jsonl\",\n",
    "}\n",
    "drug_dataset_reloaded = load_dataset(\"json\", data_files=data_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "640b2378-91ce-4300-bcb4-3dad8ce70b5b",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc0e560b-bbf7-440c-ba9f-757a9c7f317c",
   "metadata": {},
   "source": [
    "### Big data? ðŸ¤— Datasets to the rescue!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e17fa76a-b9e3-4c1c-88e0-1b9e5720208f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
